{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**AUTHORS: Suman Lohit, I-ching Wang**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification: BANK MARKETING DATASET"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Abstract: The data is related to direct marketing campaigns (phone calls) of a Portuguese banking institution. (source: https://archive.ics.uci.edu/ml/datasets/Bank+Marketing ). The classification goal is to predict if the client will subscribe to a term deposit (variable y) or not. \n",
    "\n",
    "The dataset we are using has 5000 rows and 21 columns including the target variable. Here is a brief description of the features of the dataset:\n",
    "1. age (numeric)\n",
    "2. job : type of job (categorical:\"admin.\",\"bluecollar\",\"entrepreneur\",\"housemaid\",\"management\",\"retired\",\"self-employed\",\"services\",\"student\",\"technician\",\"unemployed\")\n",
    "3. marital : marital status \n",
    "(categorical: \"divorced\",\"married\",\"single\"; note: \"divorced\" means divorced or widowed)\n",
    "4. education\n",
    "(categorical:\"basic.4y\",\"basic.6y\",\"basic.9y\",\"high.school\",\"illiterate\",\"professional.course\",\"university.degree\")\n",
    "5. default: has credit in default? (categorical: \"no\",\"yes\")\n",
    "6. housing: has housing loan? (categorical: \"no\",\"yes\")\n",
    "7. loan: has personal loan? (categorical: \"no\",\"yes\")\n",
    "   \n",
    "   Related with the last contact of the current campaign:\n",
    "8. contact: contact communication type \n",
    "(categorical: \"cellular\",\"telephone\") \n",
    "9. month: last contact month of year \n",
    "(categorical: \"mar\", ..., \"nov\", \"dec\")\n",
    "10. day_of_week: last contact day of the week \n",
    "(categorical: \"mon\",\"tue\",\"wed\",\"thu\",\"fri\")\n",
    "11. duration: last contact duration, in seconds (numeric). Important note: The duration is not known before a call is performed. Also, after the end of the call y is obviously known. \n",
    "   \n",
    "12. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14. previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15. poutcome: outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")\n",
    "      social and economic context attributes\n",
    "16. emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17. cons.price.idx: consumer price index - monthly indicator (numeric)     \n",
    "18. cons.conf.idx: consumer confidence index - monthly indicator (numeric)     \n",
    "19. euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20. nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "  Output variable (desired target):\n",
    "21. y - has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are using the preprocessed Bank dataset from Project 1. All the null values have been filled and the data has been transformed to make them suitable for Machine Learning. \r\n",
    "\r\n",
    "We run all the models from Project 1 again and store the results in a Dataframe. After that we move on to Ensemble models, PCA models and Deep Learning model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "bank = pd.read_csv(\"preprocessed_bank.csv\", index_col=0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "bank.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    age  education  housing  loan  month  day_of_week  campaign  pdays  \\\n",
       "0  56.0          0        0     1      2            0       1.0  999.0   \n",
       "1  35.0          1        1     1      2            0       1.0  999.0   \n",
       "2  54.0          0        0     1      2            0       1.0  999.0   \n",
       "3  55.0          0        1     1      2            0       1.0  999.0   \n",
       "4  32.0          2        1     1      2            0       1.0  999.0   \n",
       "\n",
       "   previous  emp.var.rate  ...  job_unemployed  marital_divorced  \\\n",
       "0       0.0           1.1  ...               0                 0   \n",
       "1       0.0           1.1  ...               0                 0   \n",
       "2       0.0           1.1  ...               0                 1   \n",
       "3       0.0           1.1  ...               0                 0   \n",
       "4       0.0           1.1  ...               0                 0   \n",
       "\n",
       "   marital_married  marital_single  contact_cellular  contact_telephone  \\\n",
       "0                1               0                 0                  1   \n",
       "1                1               0                 0                  1   \n",
       "2                0               0                 0                  1   \n",
       "3                1               0                 0                  1   \n",
       "4                1               0                 0                  1   \n",
       "\n",
       "   contact_unknown  poutcome_failure  poutcome_nonexistent  poutcome_success  \n",
       "0                0                 0                     1                 0  \n",
       "1                0                 0                     1                 0  \n",
       "2                0                 0                     1                 0  \n",
       "3                0                 0                     1                 0  \n",
       "4                0                 0                     1                 0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>...</th>\n",
       "      <th>job_unemployed</th>\n",
       "      <th>marital_divorced</th>\n",
       "      <th>marital_married</th>\n",
       "      <th>marital_single</th>\n",
       "      <th>contact_cellular</th>\n",
       "      <th>contact_telephone</th>\n",
       "      <th>contact_unknown</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "bank.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 0 to 4999\n",
      "Data columns (total 35 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   age                   5000 non-null   float64\n",
      " 1   education             5000 non-null   int64  \n",
      " 2   housing               5000 non-null   int64  \n",
      " 3   loan                  5000 non-null   int64  \n",
      " 4   month                 5000 non-null   int64  \n",
      " 5   day_of_week           5000 non-null   int64  \n",
      " 6   campaign              5000 non-null   float64\n",
      " 7   pdays                 5000 non-null   float64\n",
      " 8   previous              5000 non-null   float64\n",
      " 9   emp.var.rate          5000 non-null   float64\n",
      " 10  cons.price.idx        5000 non-null   float64\n",
      " 11  cons.conf.idx         5000 non-null   float64\n",
      " 12  euribor3m             5000 non-null   float64\n",
      " 13  nr.employed           5000 non-null   float64\n",
      " 14  y                     5000 non-null   int64  \n",
      " 15  job_admin.            5000 non-null   int64  \n",
      " 16  job_blue-collar       5000 non-null   int64  \n",
      " 17  job_entrepreneur      5000 non-null   int64  \n",
      " 18  job_housemaid         5000 non-null   int64  \n",
      " 19  job_management        5000 non-null   int64  \n",
      " 20  job_retired           5000 non-null   int64  \n",
      " 21  job_self-employed     5000 non-null   int64  \n",
      " 22  job_services          5000 non-null   int64  \n",
      " 23  job_student           5000 non-null   int64  \n",
      " 24  job_technician        5000 non-null   int64  \n",
      " 25  job_unemployed        5000 non-null   int64  \n",
      " 26  marital_divorced      5000 non-null   int64  \n",
      " 27  marital_married       5000 non-null   int64  \n",
      " 28  marital_single        5000 non-null   int64  \n",
      " 29  contact_cellular      5000 non-null   int64  \n",
      " 30  contact_telephone     5000 non-null   int64  \n",
      " 31  contact_unknown       5000 non-null   int64  \n",
      " 32  poutcome_failure      5000 non-null   int64  \n",
      " 33  poutcome_nonexistent  5000 non-null   int64  \n",
      " 34  poutcome_success      5000 non-null   int64  \n",
      "dtypes: float64(9), int64(26)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "X and Y datasets are split into training and test datasets individually. We use a MinMaxScaler to transform the features to avoid any distortions."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We split the Preprocessed data into Target (Y) and feature (X) datasets"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "colIndexes= bank.drop(['y'], axis=1).columns\r\n",
    "X= bank[colIndexes]\r\n",
    "Y= bank.y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "import random\r\n",
    "random.seed(0)\r\n",
    "X_train_org, X_test_org, Y_train, Y_test= train_test_split(X,Y,random_state=0)\r\n",
    "scaler= MinMaxScaler()\r\n",
    "X_train= scaler.fit_transform(X_train_org)\r\n",
    "X_test= scaler.transform(X_test_org)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now build various Classification Models paired with a Gridsearch Cross validation to find the optimal hyperparameters. \n",
    "\n",
    "Proclaiming most data points to be 'no' would give us a good accuracy, however, it is not helpful. We should focus on identifying the 'yes' outcomes correctly.\n",
    "Since we are more concerned with finding most 'yes' values correctly even if it means a few 'no's are falsely classified as 'yes', our evaluation criterion is going to be **\"RECALL\"**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Creating an empty DataFrame for the model results.\r\n",
    "\r\n",
    "results_recall_df = pd.DataFrame(columns=['model','test_score','recall_score'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.metrics import recall_score, precision_score\r\n",
    "from sklearn.model_selection import StratifiedKFold\r\n",
    "\r\n",
    "\r\n",
    "random.seed(0)\r\n",
    "\r\n",
    "grid_params= {'n_neighbors': [3,4,5,8,10,15,20],'weights':['distance'],'metric':['euclidean']}\r\n",
    "\r\n",
    "gs_knn= GridSearchCV(KNeighborsClassifier(), grid_params, cv= StratifiedKFold(n_splits=5,random_state=0, shuffle=True) ,scoring = 'recall',return_train_score=True, verbose=1)\r\n",
    "gs_results= gs_knn.fit(X_train, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(gs_results.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(gs_results.best_score_))\r\n",
    "\r\n",
    "gs_best_knn = KNeighborsClassifier(n_neighbors = gs_results.best_params_['n_neighbors'],metric=gs_results.best_params_['metric'],weights=gs_results.best_params_['weights'])\r\n",
    "gs_best_knn.fit(X_train,Y_train)\r\n",
    "print(f'test score : {gs_best_knn.score(X_test, Y_test)}')\r\n",
    "knn_Y_predict = gs_best_knn.predict(X_test)\r\n",
    "print('Recall :{}'.format(recall_score(Y_test,knn_Y_predict)))\r\n",
    "\r\n",
    "#results = pd.DataFrame(gs_knn.cv_results_)\r\n",
    "\r\n",
    "results_recall_df =  results_recall_df.append({'model':'knn','test_score':gs_best_knn.score(X_test, Y_test),'recall_score':recall_score(Y_test,knn_Y_predict)},ignore_index=True)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
      "Best parameters: {'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'}\n",
      "Best cross-validation score: 0.55\n",
      "test score : 0.7056\n",
      "Recall :0.5931558935361216\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Cross-validation score of this model is 0.55 and Recall score is 0.59. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "import warnings\r\n",
    "\r\n",
    "grid_params= {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['lbfgs','saga',] }\r\n",
    "\r\n",
    "Logreg = GridSearchCV(LogisticRegression(), param_grid = grid_params, cv = 5, n_jobs=-1, scoring= 'recall')\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "\r\n",
    "best_logreg = Logreg.fit(X_train, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(Logreg.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(Logreg.best_score_))\r\n",
    "# Logreg.cv_results_"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best cross-validation score: 0.65\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "logL2= LogisticRegression(penalty= Logreg.best_params_['penalty'], C= Logreg.best_params_['C'], solver= Logreg.best_params_['solver'])\r\n",
    "logL2.fit(X_train, Y_train)\r\n",
    "print('train_score_l2 : {}'.format(logL2.score(X_train, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(logL2.score(X_test, Y_test)))\r\n",
    "\r\n",
    "Logreg_Y_predict = logL2.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,Logreg_Y_predict)))\r\n",
    "\r\n",
    "results_recall_df = results_recall_df.append({'model':'logistic_regression','test_score':logL2.score(X_test, Y_test),'recall_score':recall_score(Y_test,Logreg_Y_predict)},ignore_index=True)\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_score_l2 : 0.7114666666666667\n",
      "test_score_l2 : 0.6992\n",
      "Recall :0.6426\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for Logistic Regression model is C= 0.01, penalty= l1, solver= saga. When we run the model with these parameters, we get a Recall score of 0.64. We notice here that we have a better recall rate compared to that of KNN classifier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "grid_params ={'criterion': ['gini', 'entropy'], 'max_depth': [2,5,7], 'min_samples_leaf':[5,10,15],  'random_state': [0]}\r\n",
    "\r\n",
    "clf_tree = GridSearchCV(DecisionTreeClassifier(), param_grid = grid_params, cv = 5, n_jobs=-1, scoring= 'recall')\r\n",
    "\r\n",
    "best_tree = clf_tree.fit(X_train, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(clf_tree.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(clf_tree.best_score_))\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 10, 'random_state': 0}\n",
      "Best cross-validation score: 0.56\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "tree = DecisionTreeClassifier(**clf_tree.best_params_)\r\n",
    "tree.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print(\"Train score: {:.4f}\".format(tree.score(X_train, Y_train)))\r\n",
    "print(\"Test score: {:.4f}\".format(tree.score(X_test,Y_test)))\r\n",
    "\r\n",
    "tree_Ypredict = tree.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,tree_Ypredict)))\r\n",
    "\r\n",
    "results_recall_df = results_recall_df.append({'model':'decision_tree','test_score':tree.score(X_test,Y_test),'recall_score':recall_score(Y_test,tree_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train score: 0.7683\n",
      "Test score: 0.7576\n",
      "Recall :0.5913\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters obtained from the Grid Search are: criterion= 'entropy', max_depth= 5, min_samples_leaf= 10. The cross-validation score is 0.56 The decicion tree model run with these parameters provides a Recall score of 0.59."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "bank.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5000, 35)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import os\r\n",
    "import graphviz\r\n",
    "# Create DOT data\r\n",
    "from sklearn.tree import export_graphviz\r\n",
    "\r\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin'\r\n",
    "\r\n",
    "\r\n",
    "dot_data = export_graphviz(tree, out_file=None, filled=True, rounded=True, feature_names= X.columns) \r\n",
    "# Draw graph\r\n",
    "graph = graphviz.Source(dot_data) \r\n",
    "\r\n",
    "# Show graph\r\n",
    "graph "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x1364a8b0880>"
      ],
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Generated by graphviz version 2.47.3 (20210619.1520)\r\n -->\r\n<!-- Title: Tree Pages: 1 -->\r\n<svg width=\"3085pt\" height=\"581pt\"\r\n viewBox=\"0.00 0.00 3085.00 581.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 577)\">\r\n<title>Tree</title>\r\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-577 3081,-577 3081,4 -4,4\"/>\r\n<!-- 0 -->\r\n<g id=\"node1\" class=\"node\">\r\n<title>0</title>\r\n<path fill=\"#f6d3b9\" stroke=\"black\" d=\"M1246,-573C1246,-573 1114,-573 1114,-573 1108,-573 1102,-567 1102,-561 1102,-561 1102,-517 1102,-517 1102,-511 1108,-505 1114,-505 1114,-505 1246,-505 1246,-505 1252,-505 1258,-511 1258,-517 1258,-517 1258,-561 1258,-561 1258,-567 1252,-573 1246,-573\"/>\r\n<text text-anchor=\"middle\" x=\"1180\" y=\"-557.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">nr.employed &lt;= 0.469</text>\r\n<text text-anchor=\"middle\" x=\"1180\" y=\"-542.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.967</text>\r\n<text text-anchor=\"middle\" x=\"1180\" y=\"-527.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3750</text>\r\n<text text-anchor=\"middle\" x=\"1180\" y=\"-512.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2276, 1474]</text>\r\n</g>\r\n<!-- 1 -->\r\n<g id=\"node2\" class=\"node\">\r\n<title>1</title>\r\n<path fill=\"#68b4eb\" stroke=\"black\" d=\"M934,-469C934,-469 828,-469 828,-469 822,-469 816,-463 816,-457 816,-457 816,-413 816,-413 816,-407 822,-401 828,-401 828,-401 934,-401 934,-401 940,-401 946,-407 946,-413 946,-413 946,-457 946,-457 946,-463 940,-469 934,-469\"/>\r\n<text text-anchor=\"middle\" x=\"881\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pdays &lt;= 0.511</text>\r\n<text text-anchor=\"middle\" x=\"881\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.707</text>\r\n<text text-anchor=\"middle\" x=\"881\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 820</text>\r\n<text text-anchor=\"middle\" x=\"881\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [158, 662]</text>\r\n</g>\r\n<!-- 0&#45;&gt;1 -->\r\n<g id=\"edge1\" class=\"edge\">\r\n<title>0&#45;&gt;1</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1101.83,-511.33C1056.7,-495.94 1000.23,-476.67 955.69,-461.48\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"956.69,-458.12 946.09,-458.21 954.43,-464.75 956.69,-458.12\"/>\r\n<text text-anchor=\"middle\" x=\"957.12\" y=\"-476.94\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n</g>\r\n<!-- 22 -->\r\n<g id=\"node23\" class=\"node\">\r\n<title>22</title>\r\n<path fill=\"#efb185\" stroke=\"black\" d=\"M1564,-469C1564,-469 1446,-469 1446,-469 1440,-469 1434,-463 1434,-457 1434,-457 1434,-413 1434,-413 1434,-407 1440,-401 1446,-401 1446,-401 1564,-401 1564,-401 1570,-401 1576,-407 1576,-413 1576,-413 1576,-457 1576,-457 1576,-463 1570,-469 1564,-469\"/>\r\n<text text-anchor=\"middle\" x=\"1505\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">euribor3m &lt;= 0.402</text>\r\n<text text-anchor=\"middle\" x=\"1505\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.852</text>\r\n<text text-anchor=\"middle\" x=\"1505\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2930</text>\r\n<text text-anchor=\"middle\" x=\"1505\" y=\"-408.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2118, 812]</text>\r\n</g>\r\n<!-- 0&#45;&gt;22 -->\r\n<g id=\"edge22\" class=\"edge\">\r\n<title>0&#45;&gt;22</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1258.26,-513.44C1308.46,-497.68 1373.49,-477.27 1424.18,-461.36\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1425.3,-464.68 1433.8,-458.35 1423.21,-458 1425.3,-464.68\"/>\r\n<text text-anchor=\"middle\" x=\"1422.22\" y=\"-476.81\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n</g>\r\n<!-- 2 -->\r\n<g id=\"node3\" class=\"node\">\r\n<title>2</title>\r\n<path fill=\"#46a4e7\" stroke=\"black\" d=\"M519,-365C519,-365 387,-365 387,-365 381,-365 375,-359 375,-353 375,-353 375,-309 375,-309 375,-303 381,-297 387,-297 387,-297 519,-297 519,-297 525,-297 531,-303 531,-309 531,-309 531,-353 531,-353 531,-359 525,-365 519,-365\"/>\r\n<text text-anchor=\"middle\" x=\"453\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">nr.employed &lt;= 0.326</text>\r\n<text text-anchor=\"middle\" x=\"453\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.339</text>\r\n<text text-anchor=\"middle\" x=\"453\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 254</text>\r\n<text text-anchor=\"middle\" x=\"453\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [16, 238]</text>\r\n</g>\r\n<!-- 1&#45;&gt;2 -->\r\n<g id=\"edge2\" class=\"edge\">\r\n<title>1&#45;&gt;2</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M816,-418.51C742.63,-401.02 622.87,-372.48 541.13,-353\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"541.89,-349.59 531.35,-350.67 540.27,-356.4 541.89,-349.59\"/>\r\n</g>\r\n<!-- 11 -->\r\n<g id=\"node12\" class=\"node\">\r\n<title>11</title>\r\n<path fill=\"#7bbeee\" stroke=\"black\" d=\"M940,-365C940,-365 822,-365 822,-365 816,-365 810,-359 810,-353 810,-353 810,-309 810,-309 810,-303 816,-297 822,-297 822,-297 940,-297 940,-297 946,-297 952,-303 952,-309 952,-309 952,-353 952,-353 952,-359 946,-365 940,-365\"/>\r\n<text text-anchor=\"middle\" x=\"881\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">euribor3m &lt;= 0.018</text>\r\n<text text-anchor=\"middle\" x=\"881\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.813</text>\r\n<text text-anchor=\"middle\" x=\"881\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 566</text>\r\n<text text-anchor=\"middle\" x=\"881\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [142, 424]</text>\r\n</g>\r\n<!-- 1&#45;&gt;11 -->\r\n<g id=\"edge11\" class=\"edge\">\r\n<title>1&#45;&gt;11</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M881,-400.88C881,-392.78 881,-383.98 881,-375.47\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"884.5,-375.3 881,-365.3 877.5,-375.3 884.5,-375.3\"/>\r\n</g>\r\n<!-- 3 -->\r\n<g id=\"node4\" class=\"node\">\r\n<title>3</title>\r\n<path fill=\"#42a2e6\" stroke=\"black\" d=\"M306,-261C306,-261 208,-261 208,-261 202,-261 196,-255 196,-249 196,-249 196,-205 196,-205 196,-199 202,-193 208,-193 208,-193 306,-193 306,-193 312,-193 318,-199 318,-205 318,-205 318,-249 318,-249 318,-255 312,-261 306,-261\"/>\r\n<text text-anchor=\"middle\" x=\"257\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">age &lt;= 0.426</text>\r\n<text text-anchor=\"middle\" x=\"257\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.268</text>\r\n<text text-anchor=\"middle\" x=\"257\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 219</text>\r\n<text text-anchor=\"middle\" x=\"257\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 209]</text>\r\n</g>\r\n<!-- 2&#45;&gt;3 -->\r\n<g id=\"edge3\" class=\"edge\">\r\n<title>2&#45;&gt;3</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M389.36,-296.88C369.5,-286.55 347.48,-275.09 327.19,-264.53\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"328.8,-261.42 318.31,-259.91 325.57,-267.63 328.8,-261.42\"/>\r\n</g>\r\n<!-- 8 -->\r\n<g id=\"node9\" class=\"node\">\r\n<title>8</title>\r\n<path fill=\"#62b1ea\" stroke=\"black\" d=\"M499,-261C499,-261 407,-261 407,-261 401,-261 395,-255 395,-249 395,-249 395,-205 395,-205 395,-199 401,-193 407,-193 407,-193 499,-193 499,-193 505,-193 511,-199 511,-205 511,-205 511,-249 511,-249 511,-255 505,-261 499,-261\"/>\r\n<text text-anchor=\"middle\" x=\"453\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">age &lt;= 0.34</text>\r\n<text text-anchor=\"middle\" x=\"453\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.661</text>\r\n<text text-anchor=\"middle\" x=\"453\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 35</text>\r\n<text text-anchor=\"middle\" x=\"453\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 29]</text>\r\n</g>\r\n<!-- 2&#45;&gt;8 -->\r\n<g id=\"edge8\" class=\"edge\">\r\n<title>2&#45;&gt;8</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M453,-296.88C453,-288.78 453,-279.98 453,-271.47\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"456.5,-271.3 453,-261.3 449.5,-271.3 456.5,-271.3\"/>\r\n</g>\r\n<!-- 4 -->\r\n<g id=\"node5\" class=\"node\">\r\n<title>4</title>\r\n<path fill=\"#46a4e7\" stroke=\"black\" d=\"M174,-157C174,-157 76,-157 76,-157 70,-157 64,-151 64,-145 64,-145 64,-101 64,-101 64,-95 70,-89 76,-89 76,-89 174,-89 174,-89 180,-89 186,-95 186,-101 186,-101 186,-145 186,-145 186,-151 180,-157 174,-157\"/>\r\n<text text-anchor=\"middle\" x=\"125\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">month &lt;= 0.278</text>\r\n<text text-anchor=\"middle\" x=\"125\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.34</text>\r\n<text text-anchor=\"middle\" x=\"125\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 158</text>\r\n<text text-anchor=\"middle\" x=\"125\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [10, 148]</text>\r\n</g>\r\n<!-- 3&#45;&gt;4 -->\r\n<g id=\"edge4\" class=\"edge\">\r\n<title>3&#45;&gt;4</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M214.14,-192.88C202.04,-183.53 188.75,-173.26 176.21,-163.57\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"178.15,-160.64 168.09,-157.3 173.87,-166.18 178.15,-160.64\"/>\r\n</g>\r\n<!-- 7 -->\r\n<g id=\"node8\" class=\"node\">\r\n<title>7</title>\r\n<path fill=\"#399de5\" stroke=\"black\" d=\"M297.5,-149.5C297.5,-149.5 216.5,-149.5 216.5,-149.5 210.5,-149.5 204.5,-143.5 204.5,-137.5 204.5,-137.5 204.5,-108.5 204.5,-108.5 204.5,-102.5 210.5,-96.5 216.5,-96.5 216.5,-96.5 297.5,-96.5 297.5,-96.5 303.5,-96.5 309.5,-102.5 309.5,-108.5 309.5,-108.5 309.5,-137.5 309.5,-137.5 309.5,-143.5 303.5,-149.5 297.5,-149.5\"/>\r\n<text text-anchor=\"middle\" x=\"257\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n<text text-anchor=\"middle\" x=\"257\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 61</text>\r\n<text text-anchor=\"middle\" x=\"257\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 61]</text>\r\n</g>\r\n<!-- 3&#45;&gt;7 -->\r\n<g id=\"edge7\" class=\"edge\">\r\n<title>3&#45;&gt;7</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M257,-192.88C257,-182.33 257,-170.6 257,-159.85\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"260.5,-159.52 257,-149.52 253.5,-159.52 260.5,-159.52\"/>\r\n</g>\r\n<!-- 5 -->\r\n<g id=\"node6\" class=\"node\">\r\n<title>5</title>\r\n<path fill=\"#5eafea\" stroke=\"black\" d=\"M104,-53C104,-53 12,-53 12,-53 6,-53 0,-47 0,-41 0,-41 0,-12 0,-12 0,-6 6,0 12,0 12,0 104,0 104,0 110,0 116,-6 116,-12 116,-12 116,-41 116,-41 116,-47 110,-53 104,-53\"/>\r\n<text text-anchor=\"middle\" x=\"58\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.629</text>\r\n<text text-anchor=\"middle\" x=\"58\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 38</text>\r\n<text text-anchor=\"middle\" x=\"58\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 32]</text>\r\n</g>\r\n<!-- 4&#45;&gt;5 -->\r\n<g id=\"edge5\" class=\"edge\">\r\n<title>4&#45;&gt;5</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M101.57,-88.95C95.28,-80.07 88.46,-70.46 82.13,-61.54\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"84.89,-59.37 76.25,-53.24 79.18,-63.42 84.89,-59.37\"/>\r\n</g>\r\n<!-- 6 -->\r\n<g id=\"node7\" class=\"node\">\r\n<title>6</title>\r\n<path fill=\"#40a0e6\" stroke=\"black\" d=\"M238,-53C238,-53 146,-53 146,-53 140,-53 134,-47 134,-41 134,-41 134,-12 134,-12 134,-6 140,0 146,0 146,0 238,0 238,0 244,0 250,-6 250,-12 250,-12 250,-41 250,-41 250,-47 244,-53 238,-53\"/>\r\n<text text-anchor=\"middle\" x=\"192\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.211</text>\r\n<text text-anchor=\"middle\" x=\"192\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\r\n<text text-anchor=\"middle\" x=\"192\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 116]</text>\r\n</g>\r\n<!-- 4&#45;&gt;6 -->\r\n<g id=\"edge6\" class=\"edge\">\r\n<title>4&#45;&gt;6</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M148.43,-88.95C154.72,-80.07 161.54,-70.46 167.87,-61.54\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"170.82,-63.42 173.75,-53.24 165.11,-59.37 170.82,-63.42\"/>\r\n</g>\r\n<!-- 9 -->\r\n<g id=\"node10\" class=\"node\">\r\n<title>9</title>\r\n<path fill=\"#45a3e7\" stroke=\"black\" d=\"M424,-149.5C424,-149.5 340,-149.5 340,-149.5 334,-149.5 328,-143.5 328,-137.5 328,-137.5 328,-108.5 328,-108.5 328,-102.5 334,-96.5 340,-96.5 340,-96.5 424,-96.5 424,-96.5 430,-96.5 436,-102.5 436,-108.5 436,-108.5 436,-137.5 436,-137.5 436,-143.5 430,-149.5 424,-149.5\"/>\r\n<text text-anchor=\"middle\" x=\"382\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.31</text>\r\n<text text-anchor=\"middle\" x=\"382\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\r\n<text text-anchor=\"middle\" x=\"382\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 17]</text>\r\n</g>\r\n<!-- 8&#45;&gt;9 -->\r\n<g id=\"edge9\" class=\"edge\">\r\n<title>8&#45;&gt;9</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M429.95,-192.88C422.14,-181.67 413.41,-169.13 405.56,-157.85\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"408.35,-155.73 399.76,-149.52 402.6,-159.73 408.35,-155.73\"/>\r\n</g>\r\n<!-- 10 -->\r\n<g id=\"node11\" class=\"node\">\r\n<title>10</title>\r\n<path fill=\"#8bc6f0\" stroke=\"black\" d=\"M558,-149.5C558,-149.5 466,-149.5 466,-149.5 460,-149.5 454,-143.5 454,-137.5 454,-137.5 454,-108.5 454,-108.5 454,-102.5 460,-96.5 466,-96.5 466,-96.5 558,-96.5 558,-96.5 564,-96.5 570,-102.5 570,-108.5 570,-108.5 570,-137.5 570,-137.5 570,-143.5 564,-149.5 558,-149.5\"/>\r\n<text text-anchor=\"middle\" x=\"512\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.874</text>\r\n<text text-anchor=\"middle\" x=\"512\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 17</text>\r\n<text text-anchor=\"middle\" x=\"512\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [5, 12]</text>\r\n</g>\r\n<!-- 8&#45;&gt;10 -->\r\n<g id=\"edge10\" class=\"edge\">\r\n<title>8&#45;&gt;10</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M472.16,-192.88C478.58,-181.78 485.76,-169.37 492.23,-158.18\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"495.26,-159.93 497.24,-149.52 489.2,-156.42 495.26,-159.93\"/>\r\n</g>\r\n<!-- 12 -->\r\n<g id=\"node13\" class=\"node\">\r\n<title>12</title>\r\n<path fill=\"#59ade9\" stroke=\"black\" d=\"M847,-261C847,-261 755,-261 755,-261 749,-261 743,-255 743,-249 743,-249 743,-205 743,-205 743,-199 749,-193 755,-193 755,-193 847,-193 847,-193 853,-193 859,-199 859,-205 859,-205 859,-249 859,-249 859,-255 853,-261 847,-261\"/>\r\n<text text-anchor=\"middle\" x=\"801\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">age &lt;= 0.611</text>\r\n<text text-anchor=\"middle\" x=\"801\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.585</text>\r\n<text text-anchor=\"middle\" x=\"801\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 107</text>\r\n<text text-anchor=\"middle\" x=\"801\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 92]</text>\r\n</g>\r\n<!-- 11&#45;&gt;12 -->\r\n<g id=\"edge12\" class=\"edge\">\r\n<title>11&#45;&gt;12</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M855.03,-296.88C848.11,-288.07 840.55,-278.43 833.34,-269.24\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"836.04,-267.01 827.12,-261.3 830.53,-271.33 836.04,-267.01\"/>\r\n</g>\r\n<!-- 17 -->\r\n<g id=\"node18\" class=\"node\">\r\n<title>17</title>\r\n<path fill=\"#85c2ef\" stroke=\"black\" d=\"M1027,-261C1027,-261 895,-261 895,-261 889,-261 883,-255 883,-249 883,-249 883,-205 883,-205 883,-199 889,-193 895,-193 895,-193 1027,-193 1027,-193 1033,-193 1039,-199 1039,-205 1039,-205 1039,-249 1039,-249 1039,-255 1033,-261 1027,-261\"/>\r\n<text text-anchor=\"middle\" x=\"961\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">emp.var.rate &lt;= 0.594</text>\r\n<text text-anchor=\"middle\" x=\"961\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.851</text>\r\n<text text-anchor=\"middle\" x=\"961\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 459</text>\r\n<text text-anchor=\"middle\" x=\"961\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [127, 332]</text>\r\n</g>\r\n<!-- 11&#45;&gt;17 -->\r\n<g id=\"edge17\" class=\"edge\">\r\n<title>11&#45;&gt;17</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M906.97,-296.88C913.89,-288.07 921.45,-278.43 928.66,-269.24\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"931.47,-271.33 934.88,-261.3 925.96,-267.01 931.47,-271.33\"/>\r\n</g>\r\n<!-- 13 -->\r\n<g id=\"node14\" class=\"node\">\r\n<title>13</title>\r\n<path fill=\"#5eafea\" stroke=\"black\" d=\"M718,-157C718,-157 600,-157 600,-157 594,-157 588,-151 588,-145 588,-145 588,-101 588,-101 588,-95 594,-89 600,-89 600,-89 718,-89 718,-89 724,-89 730,-95 730,-101 730,-101 730,-145 730,-145 730,-151 724,-157 718,-157\"/>\r\n<text text-anchor=\"middle\" x=\"659\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">euribor3m &lt;= 0.003</text>\r\n<text text-anchor=\"middle\" x=\"659\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.629</text>\r\n<text text-anchor=\"middle\" x=\"659\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 95</text>\r\n<text text-anchor=\"middle\" x=\"659\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [15, 80]</text>\r\n</g>\r\n<!-- 12&#45;&gt;13 -->\r\n<g id=\"edge13\" class=\"edge\">\r\n<title>12&#45;&gt;13</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M754.9,-192.88C741.75,-183.44 727.3,-173.06 713.7,-163.29\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"715.52,-160.29 705.36,-157.3 711.44,-165.98 715.52,-160.29\"/>\r\n</g>\r\n<!-- 16 -->\r\n<g id=\"node17\" class=\"node\">\r\n<title>16</title>\r\n<path fill=\"#399de5\" stroke=\"black\" d=\"M841.5,-149.5C841.5,-149.5 760.5,-149.5 760.5,-149.5 754.5,-149.5 748.5,-143.5 748.5,-137.5 748.5,-137.5 748.5,-108.5 748.5,-108.5 748.5,-102.5 754.5,-96.5 760.5,-96.5 760.5,-96.5 841.5,-96.5 841.5,-96.5 847.5,-96.5 853.5,-102.5 853.5,-108.5 853.5,-108.5 853.5,-137.5 853.5,-137.5 853.5,-143.5 847.5,-149.5 841.5,-149.5\"/>\r\n<text text-anchor=\"middle\" x=\"801\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n<text text-anchor=\"middle\" x=\"801\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12</text>\r\n<text text-anchor=\"middle\" x=\"801\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 12]</text>\r\n</g>\r\n<!-- 12&#45;&gt;16 -->\r\n<g id=\"edge16\" class=\"edge\">\r\n<title>12&#45;&gt;16</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M801,-192.88C801,-182.33 801,-170.6 801,-159.85\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"804.5,-159.52 801,-149.52 797.5,-159.52 804.5,-159.52\"/>\r\n</g>\r\n<!-- 14 -->\r\n<g id=\"node15\" class=\"node\">\r\n<title>14</title>\r\n<path fill=\"#42a2e6\" stroke=\"black\" d=\"M581,-53C581,-53 489,-53 489,-53 483,-53 477,-47 477,-41 477,-41 477,-12 477,-12 477,-6 483,0 489,0 489,0 581,0 581,0 587,0 593,-6 593,-12 593,-12 593,-41 593,-41 593,-47 587,-53 581,-53\"/>\r\n<text text-anchor=\"middle\" x=\"535\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.267</text>\r\n<text text-anchor=\"middle\" x=\"535\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 22</text>\r\n<text text-anchor=\"middle\" x=\"535\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 21]</text>\r\n</g>\r\n<!-- 13&#45;&gt;14 -->\r\n<g id=\"edge14\" class=\"edge\">\r\n<title>13&#45;&gt;14</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M615.63,-88.95C603.03,-79.34 589.29,-68.87 576.79,-59.34\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"578.85,-56.51 568.77,-53.24 574.6,-62.08 578.85,-56.51\"/>\r\n</g>\r\n<!-- 15 -->\r\n<g id=\"node16\" class=\"node\">\r\n<title>15</title>\r\n<path fill=\"#68b4eb\" stroke=\"black\" d=\"M715,-53C715,-53 623,-53 623,-53 617,-53 611,-47 611,-41 611,-41 611,-12 611,-12 611,-6 617,0 623,0 623,0 715,0 715,0 721,0 727,-6 727,-12 727,-12 727,-41 727,-41 727,-47 721,-53 715,-53\"/>\r\n<text text-anchor=\"middle\" x=\"669\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.705</text>\r\n<text text-anchor=\"middle\" x=\"669\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 73</text>\r\n<text text-anchor=\"middle\" x=\"669\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [14, 59]</text>\r\n</g>\r\n<!-- 13&#45;&gt;15 -->\r\n<g id=\"edge15\" class=\"edge\">\r\n<title>13&#45;&gt;15</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M662.5,-88.95C663.38,-80.62 664.33,-71.65 665.22,-63.2\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"668.7,-63.55 666.28,-53.24 661.74,-62.81 668.7,-63.55\"/>\r\n</g>\r\n<!-- 18 -->\r\n<g id=\"node19\" class=\"node\">\r\n<title>18</title>\r\n<path fill=\"#88c4ef\" stroke=\"black\" d=\"M1038,-157C1038,-157 884,-157 884,-157 878,-157 872,-151 872,-145 872,-145 872,-101 872,-101 872,-95 878,-89 884,-89 884,-89 1038,-89 1038,-89 1044,-89 1050,-95 1050,-101 1050,-101 1050,-145 1050,-145 1050,-151 1044,-157 1038,-157\"/>\r\n<text text-anchor=\"middle\" x=\"961\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">contact_telephone &lt;= 0.5</text>\r\n<text text-anchor=\"middle\" x=\"961\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.863</text>\r\n<text text-anchor=\"middle\" x=\"961\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 441</text>\r\n<text text-anchor=\"middle\" x=\"961\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [126, 315]</text>\r\n</g>\r\n<!-- 17&#45;&gt;18 -->\r\n<g id=\"edge18\" class=\"edge\">\r\n<title>17&#45;&gt;18</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M961,-192.88C961,-184.78 961,-175.98 961,-167.47\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"964.5,-167.3 961,-157.3 957.5,-167.3 964.5,-167.3\"/>\r\n</g>\r\n<!-- 21 -->\r\n<g id=\"node22\" class=\"node\">\r\n<title>21</title>\r\n<path fill=\"#45a3e7\" stroke=\"black\" d=\"M1164,-149.5C1164,-149.5 1080,-149.5 1080,-149.5 1074,-149.5 1068,-143.5 1068,-137.5 1068,-137.5 1068,-108.5 1068,-108.5 1068,-102.5 1074,-96.5 1080,-96.5 1080,-96.5 1164,-96.5 1164,-96.5 1170,-96.5 1176,-102.5 1176,-108.5 1176,-108.5 1176,-137.5 1176,-137.5 1176,-143.5 1170,-149.5 1164,-149.5\"/>\r\n<text text-anchor=\"middle\" x=\"1122\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.31</text>\r\n<text text-anchor=\"middle\" x=\"1122\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 18</text>\r\n<text text-anchor=\"middle\" x=\"1122\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 17]</text>\r\n</g>\r\n<!-- 17&#45;&gt;21 -->\r\n<g id=\"edge21\" class=\"edge\">\r\n<title>17&#45;&gt;21</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1013.27,-192.88C1032.54,-180.68 1054.28,-166.9 1073.23,-154.9\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1075.14,-157.83 1081.72,-149.52 1071.4,-151.92 1075.14,-157.83\"/>\r\n</g>\r\n<!-- 19 -->\r\n<g id=\"node20\" class=\"node\">\r\n<title>19</title>\r\n<path fill=\"#81c1ef\" stroke=\"black\" d=\"M943,-53C943,-53 837,-53 837,-53 831,-53 825,-47 825,-41 825,-41 825,-12 825,-12 825,-6 831,0 837,0 837,0 943,0 943,0 949,0 955,-6 955,-12 955,-12 955,-41 955,-41 955,-47 949,-53 943,-53\"/>\r\n<text text-anchor=\"middle\" x=\"890\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.838</text>\r\n<text text-anchor=\"middle\" x=\"890\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 396</text>\r\n<text text-anchor=\"middle\" x=\"890\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [106, 290]</text>\r\n</g>\r\n<!-- 18&#45;&gt;19 -->\r\n<g id=\"edge19\" class=\"edge\">\r\n<title>18&#45;&gt;19</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M936.17,-88.95C929.43,-79.98 922.13,-70.27 915.37,-61.26\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"918.14,-59.13 909.34,-53.24 912.55,-63.33 918.14,-59.13\"/>\r\n</g>\r\n<!-- 20 -->\r\n<g id=\"node21\" class=\"node\">\r\n<title>20</title>\r\n<path fill=\"#d7ebfa\" stroke=\"black\" d=\"M1077,-53C1077,-53 985,-53 985,-53 979,-53 973,-47 973,-41 973,-41 973,-12 973,-12 973,-6 979,0 985,0 985,0 1077,0 1077,0 1083,0 1089,-6 1089,-12 1089,-12 1089,-41 1089,-41 1089,-47 1083,-53 1077,-53\"/>\r\n<text text-anchor=\"middle\" x=\"1031\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.991</text>\r\n<text text-anchor=\"middle\" x=\"1031\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 45</text>\r\n<text text-anchor=\"middle\" x=\"1031\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [20, 25]</text>\r\n</g>\r\n<!-- 18&#45;&gt;20 -->\r\n<g id=\"edge20\" class=\"edge\">\r\n<title>18&#45;&gt;20</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M985.48,-88.95C992.06,-80.07 999.17,-70.46 1005.79,-61.54\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1008.8,-63.36 1011.94,-53.24 1003.17,-59.19 1008.8,-63.36\"/>\r\n</g>\r\n<!-- 23 -->\r\n<g id=\"node24\" class=\"node\">\r\n<title>23</title>\r\n<path fill=\"#fae9dd\" stroke=\"black\" d=\"M1558,-365C1558,-365 1452,-365 1452,-365 1446,-365 1440,-359 1440,-353 1440,-353 1440,-309 1440,-309 1440,-303 1446,-297 1452,-297 1452,-297 1558,-297 1558,-297 1564,-297 1570,-303 1570,-309 1570,-309 1570,-353 1570,-353 1570,-359 1564,-365 1558,-365\"/>\r\n<text text-anchor=\"middle\" x=\"1505\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pdays &lt;= 0.012</text>\r\n<text text-anchor=\"middle\" x=\"1505\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.993</text>\r\n<text text-anchor=\"middle\" x=\"1505\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 776</text>\r\n<text text-anchor=\"middle\" x=\"1505\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [425, 351]</text>\r\n</g>\r\n<!-- 22&#45;&gt;23 -->\r\n<g id=\"edge23\" class=\"edge\">\r\n<title>22&#45;&gt;23</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1505,-400.88C1505,-392.78 1505,-383.98 1505,-375.47\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1508.5,-375.3 1505,-365.3 1501.5,-375.3 1508.5,-375.3\"/>\r\n</g>\r\n<!-- 36 -->\r\n<g id=\"node37\" class=\"node\">\r\n<title>36</title>\r\n<path fill=\"#eca36f\" stroke=\"black\" d=\"M2321.5,-365C2321.5,-365 2180.5,-365 2180.5,-365 2174.5,-365 2168.5,-359 2168.5,-353 2168.5,-353 2168.5,-309 2168.5,-309 2168.5,-303 2174.5,-297 2180.5,-297 2180.5,-297 2321.5,-297 2321.5,-297 2327.5,-297 2333.5,-303 2333.5,-309 2333.5,-309 2333.5,-353 2333.5,-353 2333.5,-359 2327.5,-365 2321.5,-365\"/>\r\n<text text-anchor=\"middle\" x=\"2251\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">cons.price.idx &lt;= 0.684</text>\r\n<text text-anchor=\"middle\" x=\"2251\" y=\"-334.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.749</text>\r\n<text text-anchor=\"middle\" x=\"2251\" y=\"-319.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2154</text>\r\n<text text-anchor=\"middle\" x=\"2251\" y=\"-304.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1693, 461]</text>\r\n</g>\r\n<!-- 22&#45;&gt;36 -->\r\n<g id=\"edge36\" class=\"edge\">\r\n<title>22&#45;&gt;36</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1576.19,-424.27C1711.83,-405.72 2007.21,-365.33 2158.16,-344.69\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2158.9,-348.13 2168.33,-343.3 2157.95,-341.19 2158.9,-348.13\"/>\r\n</g>\r\n<!-- 24 -->\r\n<g id=\"node25\" class=\"node\">\r\n<title>24</title>\r\n<path fill=\"#43a2e6\" stroke=\"black\" d=\"M1445,-261C1445,-261 1353,-261 1353,-261 1347,-261 1341,-255 1341,-249 1341,-249 1341,-205 1341,-205 1341,-199 1347,-193 1353,-193 1353,-193 1445,-193 1445,-193 1451,-193 1457,-199 1457,-205 1457,-205 1457,-249 1457,-249 1457,-255 1451,-261 1445,-261\"/>\r\n<text text-anchor=\"middle\" x=\"1399\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">pdays &lt;= 0.005</text>\r\n<text text-anchor=\"middle\" x=\"1399\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.271</text>\r\n<text text-anchor=\"middle\" x=\"1399\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 43</text>\r\n<text text-anchor=\"middle\" x=\"1399\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 41]</text>\r\n</g>\r\n<!-- 23&#45;&gt;24 -->\r\n<g id=\"edge24\" class=\"edge\">\r\n<title>23&#45;&gt;24</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1470.58,-296.88C1461.14,-287.8 1450.8,-277.85 1440.98,-268.4\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1443.24,-265.71 1433.61,-261.3 1438.38,-270.76 1443.24,-265.71\"/>\r\n</g>\r\n<!-- 29 -->\r\n<g id=\"node30\" class=\"node\">\r\n<title>29</title>\r\n<path fill=\"#f8ddca\" stroke=\"black\" d=\"M1670,-261C1670,-261 1552,-261 1552,-261 1546,-261 1540,-255 1540,-249 1540,-249 1540,-205 1540,-205 1540,-199 1546,-193 1552,-193 1552,-193 1670,-193 1670,-193 1676,-193 1682,-199 1682,-205 1682,-205 1682,-249 1682,-249 1682,-255 1676,-261 1670,-261\"/>\r\n<text text-anchor=\"middle\" x=\"1611\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">euribor3m &lt;= 0.162</text>\r\n<text text-anchor=\"middle\" x=\"1611\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.983</text>\r\n<text text-anchor=\"middle\" x=\"1611\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 733</text>\r\n<text text-anchor=\"middle\" x=\"1611\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [423, 310]</text>\r\n</g>\r\n<!-- 23&#45;&gt;29 -->\r\n<g id=\"edge29\" class=\"edge\">\r\n<title>23&#45;&gt;29</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1539.42,-296.88C1548.86,-287.8 1559.2,-277.85 1569.02,-268.4\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1571.62,-270.76 1576.39,-261.3 1566.76,-265.71 1571.62,-270.76\"/>\r\n</g>\r\n<!-- 25 -->\r\n<g id=\"node26\" class=\"node\">\r\n<title>25</title>\r\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1287.5,-149.5C1287.5,-149.5 1206.5,-149.5 1206.5,-149.5 1200.5,-149.5 1194.5,-143.5 1194.5,-137.5 1194.5,-137.5 1194.5,-108.5 1194.5,-108.5 1194.5,-102.5 1200.5,-96.5 1206.5,-96.5 1206.5,-96.5 1287.5,-96.5 1287.5,-96.5 1293.5,-96.5 1299.5,-102.5 1299.5,-108.5 1299.5,-108.5 1299.5,-137.5 1299.5,-137.5 1299.5,-143.5 1293.5,-149.5 1287.5,-149.5\"/>\r\n<text text-anchor=\"middle\" x=\"1247\" y=\"-134.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n<text text-anchor=\"middle\" x=\"1247\" y=\"-119.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\r\n<text text-anchor=\"middle\" x=\"1247\" y=\"-104.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 19]</text>\r\n</g>\r\n<!-- 24&#45;&gt;25 -->\r\n<g id=\"edge25\" class=\"edge\">\r\n<title>24&#45;&gt;25</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1349.65,-192.88C1331.62,-180.79 1311.3,-167.15 1293.53,-155.22\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1295.28,-152.19 1285.03,-149.52 1291.38,-158 1295.28,-152.19\"/>\r\n</g>\r\n<!-- 26 -->\r\n<g id=\"node27\" class=\"node\">\r\n<title>26</title>\r\n<path fill=\"#4ba6e7\" stroke=\"black\" d=\"M1468,-157C1468,-157 1330,-157 1330,-157 1324,-157 1318,-151 1318,-145 1318,-145 1318,-101 1318,-101 1318,-95 1324,-89 1330,-89 1330,-89 1468,-89 1468,-89 1474,-89 1480,-95 1480,-101 1480,-101 1480,-145 1480,-145 1480,-151 1474,-157 1468,-157\"/>\r\n<text text-anchor=\"middle\" x=\"1399\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">day_of_week &lt;= 0.625</text>\r\n<text text-anchor=\"middle\" x=\"1399\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.414</text>\r\n<text text-anchor=\"middle\" x=\"1399\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 24</text>\r\n<text text-anchor=\"middle\" x=\"1399\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 22]</text>\r\n</g>\r\n<!-- 24&#45;&gt;26 -->\r\n<g id=\"edge26\" class=\"edge\">\r\n<title>24&#45;&gt;26</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1399,-192.88C1399,-184.78 1399,-175.98 1399,-167.47\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1402.5,-167.3 1399,-157.3 1395.5,-167.3 1402.5,-167.3\"/>\r\n</g>\r\n<!-- 27 -->\r\n<g id=\"node28\" class=\"node\">\r\n<title>27</title>\r\n<path fill=\"#399de5\" stroke=\"black\" d=\"M1288.5,-53C1288.5,-53 1207.5,-53 1207.5,-53 1201.5,-53 1195.5,-47 1195.5,-41 1195.5,-41 1195.5,-12 1195.5,-12 1195.5,-6 1201.5,0 1207.5,0 1207.5,0 1288.5,0 1288.5,0 1294.5,0 1300.5,-6 1300.5,-12 1300.5,-12 1300.5,-41 1300.5,-41 1300.5,-47 1294.5,-53 1288.5,-53\"/>\r\n<text text-anchor=\"middle\" x=\"1248\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n<text text-anchor=\"middle\" x=\"1248\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 11</text>\r\n<text text-anchor=\"middle\" x=\"1248\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 11]</text>\r\n</g>\r\n<!-- 26&#45;&gt;27 -->\r\n<g id=\"edge27\" class=\"edge\">\r\n<title>26&#45;&gt;27</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1346.19,-88.95C1330.55,-79.16 1313.47,-68.48 1298.02,-58.8\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1299.46,-55.57 1289.12,-53.24 1295.74,-61.51 1299.46,-55.57\"/>\r\n</g>\r\n<!-- 28 -->\r\n<g id=\"node29\" class=\"node\">\r\n<title>28</title>\r\n<path fill=\"#5dafea\" stroke=\"black\" d=\"M1423,-53C1423,-53 1331,-53 1331,-53 1325,-53 1319,-47 1319,-41 1319,-41 1319,-12 1319,-12 1319,-6 1325,0 1331,0 1331,0 1423,0 1423,0 1429,0 1435,-6 1435,-12 1435,-12 1435,-41 1435,-41 1435,-47 1429,-53 1423,-53\"/>\r\n<text text-anchor=\"middle\" x=\"1377\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.619</text>\r\n<text text-anchor=\"middle\" x=\"1377\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 13</text>\r\n<text text-anchor=\"middle\" x=\"1377\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [2, 11]</text>\r\n</g>\r\n<!-- 26&#45;&gt;28 -->\r\n<g id=\"edge28\" class=\"edge\">\r\n<title>26&#45;&gt;28</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1391.31,-88.95C1389.37,-80.62 1387.28,-71.65 1385.31,-63.2\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1388.67,-62.18 1382.99,-53.24 1381.85,-63.77 1388.67,-62.18\"/>\r\n</g>\r\n<!-- 30 -->\r\n<g id=\"node31\" class=\"node\">\r\n<title>30</title>\r\n<path fill=\"#f1bd97\" stroke=\"black\" d=\"M1668.5,-157C1668.5,-157 1553.5,-157 1553.5,-157 1547.5,-157 1541.5,-151 1541.5,-145 1541.5,-145 1541.5,-101 1541.5,-101 1541.5,-95 1547.5,-89 1553.5,-89 1553.5,-89 1668.5,-89 1668.5,-89 1674.5,-89 1680.5,-95 1680.5,-101 1680.5,-101 1680.5,-145 1680.5,-145 1680.5,-151 1674.5,-157 1668.5,-157\"/>\r\n<text text-anchor=\"middle\" x=\"1611\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">campaign &lt;= 0.132</text>\r\n<text text-anchor=\"middle\" x=\"1611\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.906</text>\r\n<text text-anchor=\"middle\" x=\"1611\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 442</text>\r\n<text text-anchor=\"middle\" x=\"1611\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [300, 142]</text>\r\n</g>\r\n<!-- 29&#45;&gt;30 -->\r\n<g id=\"edge30\" class=\"edge\">\r\n<title>29&#45;&gt;30</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1611,-192.88C1611,-184.78 1611,-175.98 1611,-167.47\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1614.5,-167.3 1611,-157.3 1607.5,-167.3 1614.5,-167.3\"/>\r\n</g>\r\n<!-- 33 -->\r\n<g id=\"node34\" class=\"node\">\r\n<title>33</title>\r\n<path fill=\"#cae5f8\" stroke=\"black\" d=\"M1839,-157C1839,-157 1733,-157 1733,-157 1727,-157 1721,-151 1721,-145 1721,-145 1721,-101 1721,-101 1721,-95 1727,-89 1733,-89 1733,-89 1839,-89 1839,-89 1845,-89 1851,-95 1851,-101 1851,-101 1851,-145 1851,-145 1851,-151 1845,-157 1839,-157\"/>\r\n<text text-anchor=\"middle\" x=\"1786\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">previous &lt;= 0.1</text>\r\n<text text-anchor=\"middle\" x=\"1786\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.983</text>\r\n<text text-anchor=\"middle\" x=\"1786\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 291</text>\r\n<text text-anchor=\"middle\" x=\"1786\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [123, 168]</text>\r\n</g>\r\n<!-- 29&#45;&gt;33 -->\r\n<g id=\"edge33\" class=\"edge\">\r\n<title>29&#45;&gt;33</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1667.82,-192.88C1684.56,-183.12 1703.02,-172.37 1720.27,-162.31\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1722.29,-165.18 1729.17,-157.12 1718.77,-159.14 1722.29,-165.18\"/>\r\n</g>\r\n<!-- 31 -->\r\n<g id=\"node32\" class=\"node\">\r\n<title>31</title>\r\n<path fill=\"#f3c3a0\" stroke=\"black\" d=\"M1571,-53C1571,-53 1465,-53 1465,-53 1459,-53 1453,-47 1453,-41 1453,-41 1453,-12 1453,-12 1453,-6 1459,0 1465,0 1465,0 1571,0 1571,0 1577,0 1583,-6 1583,-12 1583,-12 1583,-41 1583,-41 1583,-47 1577,-53 1571,-53\"/>\r\n<text text-anchor=\"middle\" x=\"1518\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.928</text>\r\n<text text-anchor=\"middle\" x=\"1518\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 414</text>\r\n<text text-anchor=\"middle\" x=\"1518\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [272, 142]</text>\r\n</g>\r\n<!-- 30&#45;&gt;31 -->\r\n<g id=\"edge31\" class=\"edge\">\r\n<title>30&#45;&gt;31</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1578.47,-88.95C1569.38,-79.71 1559.5,-69.67 1550.42,-60.44\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1552.84,-57.91 1543.33,-53.24 1547.85,-62.82 1552.84,-57.91\"/>\r\n</g>\r\n<!-- 32 -->\r\n<g id=\"node33\" class=\"node\">\r\n<title>32</title>\r\n<path fill=\"#e58139\" stroke=\"black\" d=\"M1694.5,-53C1694.5,-53 1613.5,-53 1613.5,-53 1607.5,-53 1601.5,-47 1601.5,-41 1601.5,-41 1601.5,-12 1601.5,-12 1601.5,-6 1607.5,0 1613.5,0 1613.5,0 1694.5,0 1694.5,0 1700.5,0 1706.5,-6 1706.5,-12 1706.5,-12 1706.5,-41 1706.5,-41 1706.5,-47 1700.5,-53 1694.5,-53\"/>\r\n<text text-anchor=\"middle\" x=\"1654\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.0</text>\r\n<text text-anchor=\"middle\" x=\"1654\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\r\n<text text-anchor=\"middle\" x=\"1654\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [28, 0]</text>\r\n</g>\r\n<!-- 30&#45;&gt;32 -->\r\n<g id=\"edge32\" class=\"edge\">\r\n<title>30&#45;&gt;32</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1626.04,-88.95C1629.95,-80.35 1634.18,-71.06 1638.13,-62.37\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1641.33,-63.79 1642.29,-53.24 1634.96,-60.89 1641.33,-63.79\"/>\r\n</g>\r\n<!-- 34 -->\r\n<g id=\"node35\" class=\"node\">\r\n<title>34</title>\r\n<path fill=\"#aed7f4\" stroke=\"black\" d=\"M1835,-53C1835,-53 1737,-53 1737,-53 1731,-53 1725,-47 1725,-41 1725,-41 1725,-12 1725,-12 1725,-6 1731,0 1737,0 1737,0 1835,0 1835,0 1841,0 1847,-6 1847,-12 1847,-12 1847,-41 1847,-41 1847,-47 1841,-53 1835,-53\"/>\r\n<text text-anchor=\"middle\" x=\"1786\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.952</text>\r\n<text text-anchor=\"middle\" x=\"1786\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 242</text>\r\n<text text-anchor=\"middle\" x=\"1786\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [90, 152]</text>\r\n</g>\r\n<!-- 33&#45;&gt;34 -->\r\n<g id=\"edge34\" class=\"edge\">\r\n<title>33&#45;&gt;34</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1786,-88.95C1786,-80.72 1786,-71.85 1786,-63.48\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1789.5,-63.24 1786,-53.24 1782.5,-63.24 1789.5,-63.24\"/>\r\n</g>\r\n<!-- 35 -->\r\n<g id=\"node36\" class=\"node\">\r\n<title>35</title>\r\n<path fill=\"#f2be99\" stroke=\"black\" d=\"M1969,-53C1969,-53 1877,-53 1877,-53 1871,-53 1865,-47 1865,-41 1865,-41 1865,-12 1865,-12 1865,-6 1871,0 1877,0 1877,0 1969,0 1969,0 1975,0 1981,-6 1981,-12 1981,-12 1981,-41 1981,-41 1981,-47 1975,-53 1969,-53\"/>\r\n<text text-anchor=\"middle\" x=\"1923\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.911</text>\r\n<text text-anchor=\"middle\" x=\"1923\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 49</text>\r\n<text text-anchor=\"middle\" x=\"1923\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [33, 16]</text>\r\n</g>\r\n<!-- 33&#45;&gt;35 -->\r\n<g id=\"edge35\" class=\"edge\">\r\n<title>33&#45;&gt;35</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M1833.92,-88.95C1847.97,-79.25 1863.31,-68.68 1877.23,-59.07\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"1879.44,-61.8 1885.69,-53.24 1875.47,-56.03 1879.44,-61.8\"/>\r\n</g>\r\n<!-- 37 -->\r\n<g id=\"node38\" class=\"node\">\r\n<title>37</title>\r\n<path fill=\"#edaa79\" stroke=\"black\" d=\"M2308.5,-261C2308.5,-261 2193.5,-261 2193.5,-261 2187.5,-261 2181.5,-255 2181.5,-249 2181.5,-249 2181.5,-205 2181.5,-205 2181.5,-199 2187.5,-193 2193.5,-193 2193.5,-193 2308.5,-193 2308.5,-193 2314.5,-193 2320.5,-199 2320.5,-205 2320.5,-205 2320.5,-249 2320.5,-249 2320.5,-255 2314.5,-261 2308.5,-261\"/>\r\n<text text-anchor=\"middle\" x=\"2251\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">education &lt;= 0.167</text>\r\n<text text-anchor=\"middle\" x=\"2251\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.803</text>\r\n<text text-anchor=\"middle\" x=\"2251\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1234</text>\r\n<text text-anchor=\"middle\" x=\"2251\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [932, 302]</text>\r\n</g>\r\n<!-- 36&#45;&gt;37 -->\r\n<g id=\"edge37\" class=\"edge\">\r\n<title>36&#45;&gt;37</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2251,-296.88C2251,-288.78 2251,-279.98 2251,-271.47\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2254.5,-271.3 2251,-261.3 2247.5,-271.3 2254.5,-271.3\"/>\r\n</g>\r\n<!-- 44 -->\r\n<g id=\"node45\" class=\"node\">\r\n<title>44</title>\r\n<path fill=\"#ea9b62\" stroke=\"black\" d=\"M2714,-261C2714,-261 2608,-261 2608,-261 2602,-261 2596,-255 2596,-249 2596,-249 2596,-205 2596,-205 2596,-199 2602,-193 2608,-193 2608,-193 2714,-193 2714,-193 2720,-193 2726,-199 2726,-205 2726,-205 2726,-249 2726,-249 2726,-255 2720,-261 2714,-261\"/>\r\n<text text-anchor=\"middle\" x=\"2661\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">age &lt;= 0.352</text>\r\n<text text-anchor=\"middle\" x=\"2661\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.664</text>\r\n<text text-anchor=\"middle\" x=\"2661\" y=\"-215.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 920</text>\r\n<text text-anchor=\"middle\" x=\"2661\" y=\"-200.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [761, 159]</text>\r\n</g>\r\n<!-- 36&#45;&gt;44 -->\r\n<g id=\"edge44\" class=\"edge\">\r\n<title>36&#45;&gt;44</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2333.97,-309.36C2407.72,-291.01 2514.59,-264.42 2585.87,-246.69\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2586.82,-250.06 2595.68,-244.25 2585.13,-243.27 2586.82,-250.06\"/>\r\n</g>\r\n<!-- 38 -->\r\n<g id=\"node39\" class=\"node\">\r\n<title>38</title>\r\n<path fill=\"#e99457\" stroke=\"black\" d=\"M2228,-157C2228,-157 2090,-157 2090,-157 2084,-157 2078,-151 2078,-145 2078,-145 2078,-101 2078,-101 2078,-95 2084,-89 2090,-89 2090,-89 2228,-89 2228,-89 2234,-89 2240,-95 2240,-101 2240,-101 2240,-145 2240,-145 2240,-151 2234,-157 2228,-157\"/>\r\n<text text-anchor=\"middle\" x=\"2159\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">day_of_week &lt;= 0.125</text>\r\n<text text-anchor=\"middle\" x=\"2159\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.561</text>\r\n<text text-anchor=\"middle\" x=\"2159\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 99</text>\r\n<text text-anchor=\"middle\" x=\"2159\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [86, 13]</text>\r\n</g>\r\n<!-- 37&#45;&gt;38 -->\r\n<g id=\"edge38\" class=\"edge\">\r\n<title>37&#45;&gt;38</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2221.13,-192.88C2213.1,-183.98 2204.31,-174.24 2195.94,-164.96\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2198.33,-162.38 2189.03,-157.3 2193.13,-167.07 2198.33,-162.38\"/>\r\n</g>\r\n<!-- 41 -->\r\n<g id=\"node42\" class=\"node\">\r\n<title>41</title>\r\n<path fill=\"#eeac7d\" stroke=\"black\" d=\"M2417.5,-157C2417.5,-157 2270.5,-157 2270.5,-157 2264.5,-157 2258.5,-151 2258.5,-145 2258.5,-145 2258.5,-101 2258.5,-101 2258.5,-95 2264.5,-89 2270.5,-89 2270.5,-89 2417.5,-89 2417.5,-89 2423.5,-89 2429.5,-95 2429.5,-101 2429.5,-101 2429.5,-145 2429.5,-145 2429.5,-151 2423.5,-157 2417.5,-157\"/>\r\n<text text-anchor=\"middle\" x=\"2344\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">poutcome_failure &lt;= 0.5</text>\r\n<text text-anchor=\"middle\" x=\"2344\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.819</text>\r\n<text text-anchor=\"middle\" x=\"2344\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1135</text>\r\n<text text-anchor=\"middle\" x=\"2344\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [846, 289]</text>\r\n</g>\r\n<!-- 37&#45;&gt;41 -->\r\n<g id=\"edge41\" class=\"edge\">\r\n<title>37&#45;&gt;41</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2281.19,-192.88C2289.32,-183.98 2298.2,-174.24 2306.66,-164.96\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2309.49,-167.05 2313.64,-157.3 2304.31,-162.33 2309.49,-167.05\"/>\r\n</g>\r\n<!-- 39 -->\r\n<g id=\"node40\" class=\"node\">\r\n<title>39</title>\r\n<path fill=\"#f1bb94\" stroke=\"black\" d=\"M2092.5,-53C2092.5,-53 2011.5,-53 2011.5,-53 2005.5,-53 1999.5,-47 1999.5,-41 1999.5,-41 1999.5,-12 1999.5,-12 1999.5,-6 2005.5,0 2011.5,0 2011.5,0 2092.5,0 2092.5,0 2098.5,0 2104.5,-6 2104.5,-12 2104.5,-12 2104.5,-41 2104.5,-41 2104.5,-47 2098.5,-53 2092.5,-53\"/>\r\n<text text-anchor=\"middle\" x=\"2052\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.9</text>\r\n<text text-anchor=\"middle\" x=\"2052\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19</text>\r\n<text text-anchor=\"middle\" x=\"2052\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [13, 6]</text>\r\n</g>\r\n<!-- 38&#45;&gt;39 -->\r\n<g id=\"edge39\" class=\"edge\">\r\n<title>38&#45;&gt;39</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2121.58,-88.95C2110.91,-79.53 2099.3,-69.27 2088.68,-59.89\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2090.95,-57.23 2081.14,-53.24 2086.32,-62.48 2090.95,-57.23\"/>\r\n</g>\r\n<!-- 40 -->\r\n<g id=\"node41\" class=\"node\">\r\n<title>40</title>\r\n<path fill=\"#e78d4c\" stroke=\"black\" d=\"M2227,-53C2227,-53 2135,-53 2135,-53 2129,-53 2123,-47 2123,-41 2123,-41 2123,-12 2123,-12 2123,-6 2129,0 2135,0 2135,0 2227,0 2227,0 2233,0 2239,-6 2239,-12 2239,-12 2239,-41 2239,-41 2239,-47 2233,-53 2227,-53\"/>\r\n<text text-anchor=\"middle\" x=\"2181\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.428</text>\r\n<text text-anchor=\"middle\" x=\"2181\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 80</text>\r\n<text text-anchor=\"middle\" x=\"2181\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [73, 7]</text>\r\n</g>\r\n<!-- 38&#45;&gt;40 -->\r\n<g id=\"edge40\" class=\"edge\">\r\n<title>38&#45;&gt;40</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2166.69,-88.95C2168.63,-80.62 2170.72,-71.65 2172.69,-63.2\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2176.15,-63.77 2175.01,-53.24 2169.33,-62.18 2176.15,-63.77\"/>\r\n</g>\r\n<!-- 42 -->\r\n<g id=\"node43\" class=\"node\">\r\n<title>42</title>\r\n<path fill=\"#eeae7f\" stroke=\"black\" d=\"M2375,-53C2375,-53 2269,-53 2269,-53 2263,-53 2257,-47 2257,-41 2257,-41 2257,-12 2257,-12 2257,-6 2263,0 2269,0 2269,0 2375,0 2375,0 2381,0 2387,-6 2387,-12 2387,-12 2387,-41 2387,-41 2387,-47 2381,-53 2375,-53\"/>\r\n<text text-anchor=\"middle\" x=\"2322\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.83</text>\r\n<text text-anchor=\"middle\" x=\"2322\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1076</text>\r\n<text text-anchor=\"middle\" x=\"2322\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [794, 282]</text>\r\n</g>\r\n<!-- 41&#45;&gt;42 -->\r\n<g id=\"edge42\" class=\"edge\">\r\n<title>41&#45;&gt;42</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2336.31,-88.95C2334.37,-80.62 2332.28,-71.65 2330.31,-63.2\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2333.67,-62.18 2327.99,-53.24 2326.85,-63.77 2333.67,-62.18\"/>\r\n</g>\r\n<!-- 43 -->\r\n<g id=\"node44\" class=\"node\">\r\n<title>43</title>\r\n<path fill=\"#e89254\" stroke=\"black\" d=\"M2509,-53C2509,-53 2417,-53 2417,-53 2411,-53 2405,-47 2405,-41 2405,-41 2405,-12 2405,-12 2405,-6 2411,0 2417,0 2417,0 2509,0 2509,0 2515,0 2521,-6 2521,-12 2521,-12 2521,-41 2521,-41 2521,-47 2515,-53 2509,-53\"/>\r\n<text text-anchor=\"middle\" x=\"2463\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.525</text>\r\n<text text-anchor=\"middle\" x=\"2463\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 59</text>\r\n<text text-anchor=\"middle\" x=\"2463\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [52, 7]</text>\r\n</g>\r\n<!-- 41&#45;&gt;43 -->\r\n<g id=\"edge43\" class=\"edge\">\r\n<title>41&#45;&gt;43</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2385.62,-88.95C2397.6,-79.43 2410.65,-69.07 2422.56,-59.62\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2424.94,-62.2 2430.59,-53.24 2420.58,-56.71 2424.94,-62.2\"/>\r\n</g>\r\n<!-- 45 -->\r\n<g id=\"node46\" class=\"node\">\r\n<title>45</title>\r\n<path fill=\"#eb9f68\" stroke=\"black\" d=\"M2720,-157C2720,-157 2602,-157 2602,-157 2596,-157 2590,-151 2590,-145 2590,-145 2590,-101 2590,-101 2590,-95 2596,-89 2602,-89 2602,-89 2720,-89 2720,-89 2726,-89 2732,-95 2732,-101 2732,-101 2732,-145 2732,-145 2732,-151 2726,-157 2720,-157\"/>\r\n<text text-anchor=\"middle\" x=\"2661\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">euribor3m &lt;= 0.981</text>\r\n<text text-anchor=\"middle\" x=\"2661\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.708</text>\r\n<text text-anchor=\"middle\" x=\"2661\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 673</text>\r\n<text text-anchor=\"middle\" x=\"2661\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [543, 130]</text>\r\n</g>\r\n<!-- 44&#45;&gt;45 -->\r\n<g id=\"edge45\" class=\"edge\">\r\n<title>44&#45;&gt;45</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2661,-192.88C2661,-184.78 2661,-175.98 2661,-167.47\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2664.5,-167.3 2661,-157.3 2657.5,-167.3 2664.5,-167.3\"/>\r\n</g>\r\n<!-- 48 -->\r\n<g id=\"node49\" class=\"node\">\r\n<title>48</title>\r\n<path fill=\"#e89253\" stroke=\"black\" d=\"M2938,-157C2938,-157 2820,-157 2820,-157 2814,-157 2808,-151 2808,-145 2808,-145 2808,-101 2808,-101 2808,-95 2814,-89 2820,-89 2820,-89 2938,-89 2938,-89 2944,-89 2950,-95 2950,-101 2950,-101 2950,-145 2950,-145 2950,-151 2944,-157 2938,-157\"/>\r\n<text text-anchor=\"middle\" x=\"2879\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">euribor3m &lt;= 0.957</text>\r\n<text text-anchor=\"middle\" x=\"2879\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.522</text>\r\n<text text-anchor=\"middle\" x=\"2879\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 247</text>\r\n<text text-anchor=\"middle\" x=\"2879\" y=\"-96.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [218, 29]</text>\r\n</g>\r\n<!-- 44&#45;&gt;48 -->\r\n<g id=\"edge48\" class=\"edge\">\r\n<title>44&#45;&gt;48</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2726.11,-195.53C2749.03,-184.81 2775.05,-172.64 2799.05,-161.41\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2800.57,-164.56 2808.14,-157.15 2797.6,-158.22 2800.57,-164.56\"/>\r\n</g>\r\n<!-- 46 -->\r\n<g id=\"node47\" class=\"node\">\r\n<title>46</title>\r\n<path fill=\"#eb9e66\" stroke=\"black\" d=\"M2657,-53C2657,-53 2551,-53 2551,-53 2545,-53 2539,-47 2539,-41 2539,-41 2539,-12 2539,-12 2539,-6 2545,0 2551,0 2551,0 2657,0 2657,0 2663,0 2669,-6 2669,-12 2669,-12 2669,-41 2669,-41 2669,-47 2663,-53 2657,-53\"/>\r\n<text text-anchor=\"middle\" x=\"2604\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.69</text>\r\n<text text-anchor=\"middle\" x=\"2604\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 623</text>\r\n<text text-anchor=\"middle\" x=\"2604\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [508, 115]</text>\r\n</g>\r\n<!-- 45&#45;&gt;46 -->\r\n<g id=\"edge46\" class=\"edge\">\r\n<title>45&#45;&gt;46</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2641.06,-88.95C2635.77,-80.17 2630.03,-70.66 2624.7,-61.82\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2627.69,-59.99 2619.52,-53.24 2621.69,-63.61 2627.69,-59.99\"/>\r\n</g>\r\n<!-- 47 -->\r\n<g id=\"node48\" class=\"node\">\r\n<title>47</title>\r\n<path fill=\"#f0b78e\" stroke=\"black\" d=\"M2791,-53C2791,-53 2699,-53 2699,-53 2693,-53 2687,-47 2687,-41 2687,-41 2687,-12 2687,-12 2687,-6 2693,0 2699,0 2699,0 2791,0 2791,0 2797,0 2803,-6 2803,-12 2803,-12 2803,-41 2803,-41 2803,-47 2797,-53 2791,-53\"/>\r\n<text text-anchor=\"middle\" x=\"2745\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.881</text>\r\n<text text-anchor=\"middle\" x=\"2745\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\r\n<text text-anchor=\"middle\" x=\"2745\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [35, 15]</text>\r\n</g>\r\n<!-- 45&#45;&gt;47 -->\r\n<g id=\"edge47\" class=\"edge\">\r\n<title>45&#45;&gt;47</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2690.38,-88.95C2698.51,-79.8 2707.34,-69.87 2715.48,-60.71\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2718.1,-63.04 2722.12,-53.24 2712.86,-58.39 2718.1,-63.04\"/>\r\n</g>\r\n<!-- 49 -->\r\n<g id=\"node50\" class=\"node\">\r\n<title>49</title>\r\n<path fill=\"#e5833c\" stroke=\"black\" d=\"M2925,-53C2925,-53 2833,-53 2833,-53 2827,-53 2821,-47 2821,-41 2821,-41 2821,-12 2821,-12 2821,-6 2827,0 2833,0 2833,0 2925,0 2925,0 2931,0 2937,-6 2937,-12 2937,-12 2937,-41 2937,-41 2937,-47 2931,-53 2925,-53\"/>\r\n<text text-anchor=\"middle\" x=\"2879\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.126</text>\r\n<text text-anchor=\"middle\" x=\"2879\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 58</text>\r\n<text text-anchor=\"middle\" x=\"2879\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [57, 1]</text>\r\n</g>\r\n<!-- 48&#45;&gt;49 -->\r\n<g id=\"edge49\" class=\"edge\">\r\n<title>48&#45;&gt;49</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2879,-88.95C2879,-80.72 2879,-71.85 2879,-63.48\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2882.5,-63.24 2879,-53.24 2875.5,-63.24 2882.5,-63.24\"/>\r\n</g>\r\n<!-- 50 -->\r\n<g id=\"node51\" class=\"node\">\r\n<title>50</title>\r\n<path fill=\"#ea975b\" stroke=\"black\" d=\"M3065,-53C3065,-53 2967,-53 2967,-53 2961,-53 2955,-47 2955,-41 2955,-41 2955,-12 2955,-12 2955,-6 2961,0 2967,0 2967,0 3065,0 3065,0 3071,0 3077,-6 3077,-12 3077,-12 3077,-41 3077,-41 3077,-47 3071,-53 3065,-53\"/>\r\n<text text-anchor=\"middle\" x=\"3016\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">entropy = 0.605</text>\r\n<text text-anchor=\"middle\" x=\"3016\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 189</text>\r\n<text text-anchor=\"middle\" x=\"3016\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [161, 28]</text>\r\n</g>\r\n<!-- 48&#45;&gt;50 -->\r\n<g id=\"edge50\" class=\"edge\">\r\n<title>48&#45;&gt;50</title>\r\n<path fill=\"none\" stroke=\"black\" d=\"M2926.92,-88.95C2940.97,-79.25 2956.31,-68.68 2970.23,-59.07\"/>\r\n<polygon fill=\"black\" stroke=\"black\" points=\"2972.44,-61.8 2978.69,-53.24 2968.47,-56.03 2972.44,-61.8\"/>\r\n</g>\r\n</g>\r\n</svg>\r\n"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The decision tree model first splits the tree on \"nr.employed\" and the second split on \"emp.var.rate\" and \"poutcome_success\". Entropy measures the impurity of every node. Samples are the number of records that are reaching that particular node. Orange colored nodes represent nodes that contain majority of the samples that have 'no' as the 'y' outcome. Blue nodes indicate that majority of the its samples have 'yes' as the outcome.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "from mlxtend.plotting import plot_decision_regions, category_scatter\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear SVC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "from sklearn.svm import LinearSVC\r\n",
    "\r\n",
    "grid_params= {'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'random_state': [0] }\r\n",
    "\r\n",
    "clf_lsvc = GridSearchCV(LinearSVC(), param_grid = grid_params, cv = 5, n_jobs=-1, scoring= 'recall')\r\n",
    "\r\n",
    "best_lsvc = clf_lsvc.fit(X_train, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(clf_lsvc.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(clf_lsvc.best_score_))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'C': 1000, 'penalty': 'l2', 'random_state': 0}\n",
      "Best cross-validation score: 0.75\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "clf_ls= LinearSVC(penalty= clf_lsvc.best_params_['penalty'], C= clf_lsvc.best_params_['C'], random_state= clf_lsvc.best_params_['random_state'])\r\n",
    "clf_ls.fit(X_train, Y_train)\r\n",
    "print('train_score_l2 : {}'.format(clf_ls.score(X_train, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(clf_ls.score(X_test, Y_test)))\r\n",
    "\r\n",
    "clf_ls_Ypredict = clf_ls.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,clf_ls_Ypredict)))\r\n",
    "\r\n",
    "results_recall_df = results_recall_df.append({'model':'linear_svc','test_score':clf_ls.score(X_test, Y_test),'recall_score':recall_score(Y_test,clf_ls_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_score_l2 : 0.6509333333333334\n",
      "test_score_l2 : 0.6504\n",
      "Recall :0.6730\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gridsearch with Linear SVC provides the following as best parameters: C= 1000, penalty= l2. The model run with these two parameters give a test score of 0.75 and a Recall score of 0.67.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVC with kernel"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.metrics import recall_score, precision_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "# kernel= poly\r\n",
    "\r\n",
    "grid_params ={'kernel': ['poly'], 'C': [0.1,0.3], 'degree':[2,3,4],  'gamma': [0.1,0.3]}\r\n",
    "\r\n",
    "clf_poly = GridSearchCV(SVC(random_state=0), param_grid = grid_params, cv = 5, scoring= 'recall',verbose=True)\r\n",
    "\r\n",
    "clf_poly.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print(\"Best parameters: {}\".format(clf_poly.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(clf_poly.best_score_))\r\n",
    "\r\n",
    "clf_bestpoly = SVC(**clf_poly.best_params_)\r\n",
    "clf_bestpoly.fit(X_train,Y_train)\r\n",
    "\r\n",
    "print('train_score_l2 : {}'.format(clf_bestpoly.score(X_train, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(clf_bestpoly.score(X_test, Y_test)))\r\n",
    "\r\n",
    "clf_bestpoly_Ypredict = clf_bestpoly.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,clf_bestpoly_Ypredict)))\r\n",
    "\r\n",
    "results_recall_df = results_recall_df.append({'model':'kernel_poly_svc','test_score':clf_bestpoly.score(X_test, Y_test),'recall_score':recall_score(Y_test,clf_bestpoly_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'C': 0.1, 'degree': 4, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "Best cross-validation score: 0.67\n",
      "train_score_l2 : 0.7389333333333333\n",
      "test_score_l2 : 0.7376\n",
      "Recall :0.6958\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We notice that SVC With kernel 'poly', degree '4' and C = 0.1 and gamma 0.1 provides the best Recall score of the available models at 0.70. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "#kernel= rbf\r\n",
    "grid_params ={'kernel': ['rbf'], 'C': [0.1,0.3], 'degree':[2,3,4],  'gamma': [0.1,0.3]}\r\n",
    "\r\n",
    "clf_rbf = GridSearchCV(SVC(random_state=0), param_grid = grid_params, cv = 5, scoring= 'recall',verbose=True)\r\n",
    "\r\n",
    "clf_rbf.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print(\"Best parameters: {}\".format(clf_rbf.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(clf_rbf.best_score_))\r\n",
    "\r\n",
    "clf_bestrbf = SVC(**clf_rbf.best_params_)\r\n",
    "clf_bestrbf.fit(X_train,Y_train)\r\n",
    "\r\n",
    "print('train_score_l2 : {}'.format(clf_bestrbf.score(X_train, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(clf_bestrbf.score(X_test, Y_test)))\r\n",
    "\r\n",
    "clf_bestrbf_Ypredict = clf_bestrbf.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,clf_bestrbf_Ypredict)))\r\n",
    "\r\n",
    "results_recall_df = results_recall_df.append({'model':'kernel_rbf_svc','test_score':clf_bestrbf.score(X_test, Y_test),'recall_score':recall_score(Y_test,clf_bestrbf_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'C': 0.1, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best cross-validation score: 0.62\n",
      "train_score_l2 : 0.7570666666666667\n",
      "test_score_l2 : 0.7496\n",
      "Recall :0.6236\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVC With kernel 'rbf', degree '2' and C = 0.1 and gamma 0.1 provides Recall score of 0.62. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "#kernel= linear\r\n",
    "grid_params ={'kernel': ['linear'], 'C': [0.1,0.3], 'degree':[2,3,4],  'gamma': [0.1,0.3]}\r\n",
    "\r\n",
    "clf_lin = GridSearchCV(SVC(random_state=0), param_grid = grid_params, cv = 5, scoring= 'recall',verbose=True)\r\n",
    "\r\n",
    "clf_lin.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print(\"Best parameters: {}\".format(clf_lin.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(clf_lin.best_score_))\r\n",
    "\r\n",
    "clf_bestlin = SVC(**clf_lin.best_params_)\r\n",
    "clf_bestlin.fit(X_train,Y_train)\r\n",
    "\r\n",
    "print('train_score_l2 : {}'.format(clf_bestlin.score(X_train, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(clf_bestlin.score(X_test, Y_test)))\r\n",
    "\r\n",
    "clf_bestlin_Ypredict = clf_bestlin.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,clf_bestlin_Ypredict)))\r\n",
    "\r\n",
    "results_recall_df = results_recall_df.append({'model':'kernel_linear_svc','test_score':clf_bestlin.score(X_test, Y_test),'recall_score':recall_score(Y_test,clf_bestlin_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'C': 0.1, 'degree': 2, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Best cross-validation score: 0.51\n",
      "train_score_l2 : 0.7512\n",
      "test_score_l2 : 0.736\n",
      "Recall :0.5057\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We notice that SVC With kernel 'linear', degree '2' and C = 0.1 and gamma 0.1 provides a Recall score 0.51. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import precision_recall_curve\r\n",
    "\r\n",
    "grid_params ={'n_estimators': [100, 200, 500], 'max_depth': [2,4,6], 'min_samples_leaf':[5,10],  'random_state': [0], 'max_features' : [2]}\r\n",
    "\r\n",
    "rf = GridSearchCV(RandomForestClassifier(), param_grid = grid_params, cv = 5, n_jobs=-1, scoring= 'recall')\r\n",
    "\r\n",
    "rf.fit(X_train, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(rf.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(rf.best_score_))\r\n",
    "\r\n",
    "RForest= RandomForestClassifier(**rf.best_params_)\r\n",
    "RForest.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print(\"Train score: {:.4f}\".format(RForest.score(X_train, Y_train)))\r\n",
    "print(\"Test score: {:.4f}\".format(RForest.score(X_test, Y_test)))\r\n",
    "\r\n",
    "RForest_Ypredict = RForest.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test, RForest_Ypredict)))\r\n",
    "results_recall_df = results_recall_df.append({'model':'random_forest','test_score':RForest.score(X_test, Y_test),'recall_score':recall_score(Y_test,RForest_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'max_depth': 6, 'max_features': 2, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 0}\n",
      "Best cross-validation score: 0.54\n",
      "Train score: 0.7720\n",
      "Test score: 0.7632\n",
      "Recall :0.5760\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search with cross-validation is max_depth= 6, max_features= 2, min_samples_leaf= 10, n_estimators= 100. With these parameters, we run the Random Forest, we get a test score of 0.77 and a recall score of 0.58."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "results_recall_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 model  test_score  recall_score\n",
       "0                  knn      0.7056      0.593156\n",
       "1  logistic_regression      0.6992      0.642586\n",
       "2        decision_tree      0.7576      0.591255\n",
       "3           linear_svc      0.6504      0.673004\n",
       "4      kernel_poly_svc      0.7376      0.695817\n",
       "5       kernel_rbf_svc      0.7496      0.623574\n",
       "6    kernel_linear_svc      0.7360      0.505703\n",
       "7        random_forest      0.7632      0.576046"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.7056</td>\n",
       "      <td>0.593156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.642586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.591255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear_svc</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.673004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kernel_poly_svc</td>\n",
       "      <td>0.7376</td>\n",
       "      <td>0.695817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kernel_rbf_svc</td>\n",
       "      <td>0.7496</td>\n",
       "      <td>0.623574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kernel_linear_svc</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.505703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.576046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project 1 Summary"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Of all the models, Support Vector Classifier with Kernel = poly provides us the best model with a Recall Score of 0.70. \r\n",
    "Therefore, we select this model for classification purposes for future data. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are using our best model, Kernalized SVC (poly, degree 4, C 0.1, gamma 0.1), to train the model on the train dataset. We use these hyperparameters to fit the train dataset and predict values for test set. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "clf_final_svc = SVC(kernel='poly', degree=4, C = 0.1, gamma= 0.1, random_state=0)\r\n",
    "clf_final_svc.fit(X_train, Y_train)\r\n",
    "print('train_score_l2 : {}'.format(clf_final_svc.score(X_train, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(clf_final_svc.score(X_test, Y_test)))\r\n",
    "\r\n",
    "clf_final_svc_Ypredict = clf_final_svc.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,clf_final_svc_Ypredict)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_score_l2 : 0.7389333333333333\n",
      "test_score_l2 : 0.7376\n",
      "Recall :0.6958\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get a Train Score of 0.74, Test Score of 0.74, and Recall Score of about 0.70. The model correctly identifies 'yes' outcomes 70% of the time."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PROJECT 2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have gone through all the models of Project 1, we move on to other classification models. First we look into Ensemble Methods."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Voting Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# VOTING CLASSIFIERS \r\n",
    "from sklearn.ensemble import VotingClassifier\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are developing Voting Classifiers with Kernel SVC(poly), Decision tree, Logistic Regression. We are using the best parameters found in the grid search of Project 1 (above) as the parameters used for these three classifiers here. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Creating an empty DataFrame for the model results.\r\n",
    "\r\n",
    "ensdl_results_df = pd.DataFrame(columns=['model','test_score','recall_score'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hard Voting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "svc= SVC(random_state=0, kernel= 'poly', degree= 4, C= 0.1, gamma= 0.1, probability= True)\r\n",
    "svc.fit(X_train, Y_train)\r\n",
    "\r\n",
    "tree_cls= DecisionTreeClassifier(criterion='entropy', max_depth= 7, min_samples_leaf=10,random_state= 0)\r\n",
    "tree_cls.fit(X_train, Y_train)\r\n",
    "\r\n",
    "log_cls= LogisticRegression(solver= 'saga', penalty= 'l1', C=0.01, max_iter= 1000, multi_class= 'auto',random_state= 0)\r\n",
    "log_cls.fit(X_train, Y_train)\r\n",
    "\r\n",
    "# Voting= hard\r\n",
    "voting_cls= VotingClassifier(estimators= [('svc', svc), ('tree', tree_cls), ('log', log_cls)], voting= 'hard')\r\n",
    "voting_cls.fit(X_train,Y_train)\r\n",
    "voting_cls.score(X_train,Y_train)\r\n",
    "\r\n",
    "y_pred_voting= voting_cls.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test, y_pred_voting)))\r\n",
    "print('Test score: {}'.format(voting_cls.score(X_test,Y_test)))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall :0.6787\n",
      "Test score: 0.7296\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voting Classifier developed with voting method set to \"hard\" provides a recall score of 0.68 and Test score of 0.73. We store the results in the empty Dataframe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "ensdl_results_df = ensdl_results_df.append({'model':'hard_voting_cls','test_score':voting_cls.score(X_test,Y_test),'recall_score':recall_score(Y_test, y_pred_voting)},ignore_index=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Soft Voting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Voting = soft\r\n",
    "\r\n",
    "voting_soft= VotingClassifier(estimators= [('svc', svc), ('tree', tree_cls), ('log', log_cls)], voting= 'soft')\r\n",
    "voting_soft.fit(X_train,Y_train)\r\n",
    "voting_soft.score(X_train,Y_train)\r\n",
    "\r\n",
    "y_pred_soft= voting_soft.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test, y_pred_soft)))\r\n",
    "print('Test score: {}'.format(voting_soft.score(X_test,Y_test)))\r\n",
    "\r\n",
    "ensdl_results_df = ensdl_results_df.append({'model':'soft_voting_cls','test_score':voting_soft.score(X_test,Y_test),'recall_score':recall_score(Y_test, y_pred_soft)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Recall :0.6293\n",
      "Test score: 0.7504\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voting Classifier developed with voting method set to \"soft\" provides a Recall score of 0.63 and Test score of 0.75. \r\n",
    "Soft Voting Classifier has better Test score than Hard Voting Classifier. However we care more about the Recall value than Accuracy. Recall score of Hard VC(0.68) is better than that of Soft VC. Thus, Hard Voting Classifier is doing a better job than Soft Voting Classifier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bagging"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# bagging on Decision tree with gridsearch\r\n",
    "from sklearn.ensemble import BaggingClassifier\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from  sklearn.metrics import accuracy_score\r\n",
    "\r\n",
    "tree_bag= DecisionTreeClassifier( criterion= 'entropy', min_samples_leaf= 10, max_depth= 7, random_state= 0)\r\n",
    "grid_params_bag= {'max_features': [2, 5, 10, 15], 'n_estimators': [100, 200, 300, 500], 'max_samples': [0.1, 0.5, 1]}\r\n",
    "\r\n",
    "grid_bag= GridSearchCV(\r\n",
    "    BaggingClassifier(tree_bag, random_state=0), param_grid= grid_params_bag, cv= 5, scoring= 'recall')\r\n",
    "grid_bag.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print('Best parameters: {}'.format(grid_bag.best_params_))\r\n",
    "print('Best CV score:{}'.format(grid_bag.best_score_))\r\n",
    "\r\n",
    "best_tree= BaggingClassifier(tree_bag,**grid_bag.best_params_, random_state=0)\r\n",
    "best_tree.fit(X_train, Y_train)\r\n",
    "print('Train_score : {}'.format(best_tree.score(X_train, Y_train)))\r\n",
    "print('Test_score : {}'.format(best_tree.score(X_test, Y_test)))\r\n",
    "\r\n",
    "best_tree_Ypredict = best_tree.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,best_tree_Ypredict)))\r\n",
    "\r\n",
    "ensdl_results_df = ensdl_results_df.append({'model':'bagging_decision_tree','test_score':best_tree.score(X_test, Y_test),'recall_score':recall_score(Y_test,best_tree_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'max_features': 15, 'max_samples': 0.1, 'n_estimators': 500}\n",
      "Best CV score:0.5861547330796725\n",
      "Train_score : 0.7685333333333333\n",
      "Test_score : 0.7664\n",
      "Recall :0.6160\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search on Bagging with Decision Tree gives the following best parameters:max_features: 15, max_samples: 0.1, n_estimators: 500. Cross Validation is 0.59 and the Test Recall score is 0.62."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "# Bagging on KNN with Grid search\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from sklearn.metrics import recall_score, precision_score\r\n",
    "\r\n",
    "knn = KNeighborsClassifier(metric= 'euclidean', n_neighbors= 5, weights= 'distance')\r\n",
    "\r\n",
    "grid_params_bag ={'max_features': [2, 5, 10], 'n_estimators': [100, 200, 300], 'max_samples': [0.1, 0.5, 1]}\r\n",
    "\r\n",
    "grid_knn = GridSearchCV(BaggingClassifier(knn, random_state=0), param_grid = grid_params_bag, cv = 5, scoring= 'recall')\r\n",
    "\r\n",
    "grid_best_ksvc = grid_knn.fit(X_train, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(grid_knn.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_knn.best_score_))\r\n",
    "\r\n",
    "knn_bag= BaggingClassifier(knn, **grid_knn.best_params_, random_state=0)\r\n",
    "knn_bag.fit(X_train, Y_train)\r\n",
    "print('train_score_l2 : {}'.format(knn_bag.score(X_train, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(knn_bag.score(X_test, Y_test)))\r\n",
    "\r\n",
    "knn_bag_Ypredict = knn_bag.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,knn_bag_Ypredict)))\r\n",
    "\r\n",
    "ensdl_results_df = ensdl_results_df.append({'model':'bagging_knn','test_score':knn_bag.score(X_test, Y_test),'recall_score':recall_score(Y_test,knn_bag_Ypredict)},ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'max_features': 10, 'max_samples': 0.5, 'n_estimators': 300}\n",
      "Best cross-validation score: 0.55\n",
      "train_score_l2 : 0.8501333333333333\n",
      "test_score_l2 : 0.7704\n",
      "Recall :0.5932\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search on Bagging with KNN classifier gives the following best parameters: max_features: 10, max_samples: 0.5, n_estimators: 300. Cross Validation is 0.55 and the Test Recall score is 0.59."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pasting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# pasting with decision tree, gridsearch\r\n",
    "\r\n",
    "grid_tree_paste= GridSearchCV(\r\n",
    "    BaggingClassifier(tree_bag, random_state=0, bootstrap=False), param_grid= grid_params_bag, cv= 5, scoring= 'recall')\r\n",
    "grid_tree_paste.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print('Best parameters: {}'.format(grid_tree_paste.best_params_))\r\n",
    "print('Best CV score:{}'.format(grid_tree_paste.best_score_))\r\n",
    "\r\n",
    "# print('Train Recall score: {:.4f}'.format(grid_tree_paste.score(X_train, Y_train)))\r\n",
    "# print('Test Recall score: {:.4f}'.format(grid_tree_paste.score(X_test, Y_test)))\r\n",
    "\r\n",
    "tree_paste= BaggingClassifier(tree_bag,**grid_tree_paste.best_params_, random_state=0, bootstrap= False)\r\n",
    "tree_paste.fit(X_train, Y_train)\r\n",
    "print('Train_score : {}'.format(tree_paste.score(X_train, Y_train)))\r\n",
    "print('Test_score : {}'.format(tree_paste.score(X_test, Y_test)))\r\n",
    "\r\n",
    "tree_paste_Ypredict = tree_paste.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,tree_paste_Ypredict)))\r\n",
    "\r\n",
    "ensdl_results_df = ensdl_results_df.append(\r\n",
    "    {'model':'pasting_decision_tree','test_score':tree_paste.score(X_test, Y_test),'recall_score':recall_score(Y_test,tree_paste_Ypredict)},ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'max_features': 10, 'max_samples': 0.1, 'n_estimators': 300}\n",
      "Best CV score:0.5800530381644183\n",
      "Train_score : 0.7712\n",
      "Test_score : 0.7672\n",
      "Recall :0.6122\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search on Pasting with Decision Tree classifier gives the following best parameters: max_features: 10, max_samples: 0.1, n_estimators: 300. Cross Validation score is 0.58 and the Test Recall score is 0.61."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "# pasting on KNN, grid search\r\n",
    "knn = KNeighborsClassifier(metric= 'euclidean', n_neighbors= 5, weights= 'distance')\r\n",
    "\r\n",
    "grid_params_bag ={'max_features': [2, 5, 10], 'n_estimators': [100, 200, 300], 'max_samples': [0.1, 0.5, 1]}\r\n",
    "grid_knn_paste = GridSearchCV(BaggingClassifier(knn, random_state=0, bootstrap=False), param_grid = grid_params_bag, cv = 5, scoring= 'recall')\r\n",
    "\r\n",
    "grid_knn_paste.fit(X_train, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(grid_knn_paste.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_knn_paste.best_score_))\r\n",
    "\r\n",
    "knn_paste= BaggingClassifier(knn,**grid_tree_paste.best_params_, random_state=0, bootstrap= False)\r\n",
    "knn_paste.fit(X_train, Y_train)\r\n",
    "print('Train_score : {}'.format(knn_paste.score(X_train, Y_train)))\r\n",
    "print('Test_score : {}'.format(knn_paste.score(X_test, Y_test)))\r\n",
    "\r\n",
    "knn_paste_Ypredict = knn_paste.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test, knn_paste_Ypredict)))\r\n",
    "\r\n",
    "ensdl_results_df = ensdl_results_df.append({'model':'pasting_knn','test_score':knn_paste.score(X_test, Y_test),'recall_score':recall_score(Y_test, knn_paste_Ypredict)},ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'max_features': 10, 'max_samples': 0.5, 'n_estimators': 300}\n",
      "Best cross-validation score: 0.55\n",
      "Train_score : 0.7901333333333334\n",
      "Test_score : 0.7632\n",
      "Recall :0.5665\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search on Pasting with KNN classifier gives the following best parameters: max_features: 10, max_samples: 0.5, n_estimators: 300. Cross Validation score is 0.54 and the Test Recall score is 0.57."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "ensdl_results_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    model  test_score  recall_score\n",
       "0         hard_voting_cls      0.7296      0.678707\n",
       "1         soft_voting_cls      0.7504      0.629278\n",
       "2   bagging_decision_tree      0.7664      0.615970\n",
       "3             bagging_knn      0.7704      0.593156\n",
       "4   pasting_decision_tree      0.7672      0.612167\n",
       "5             pasting_knn      0.7632      0.566540\n",
       "6  adaboost_decision_tree      0.7000      0.612167\n",
       "7             adaboost_rf      0.7424      0.633080\n",
       "8       gradient_boosting      0.7216      0.617871\n",
       "9           deep_learning      0.7224      0.724335"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard_voting_cls</td>\n",
       "      <td>0.7296</td>\n",
       "      <td>0.678707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soft_voting_cls</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>0.629278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagging_decision_tree</td>\n",
       "      <td>0.7664</td>\n",
       "      <td>0.615970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bagging_knn</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.593156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pasting_decision_tree</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>0.612167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pasting_knn</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.566540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adaboost_decision_tree</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.612167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost_rf</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.633080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0.7216</td>\n",
       "      <td>0.617871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>0.7224</td>\n",
       "      <td>0.724335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparison of Bagging vs. Pasting models\r\n",
    "For Decision tree model, Bagging classifier gives a slightly better result (0.62) than Pasting (0.61).\r\n",
    "For KNN model, again, Bagging classifier gives a better result (0.59) than Pasting (0.57)\r\n",
    "\r\n",
    "Decision tree with Bagging is giving an improved model (0.62 Recall Score) over Decision tree without Bagging, that is, the original model (0.59 Recall Score).\r\n",
    "KNN with Bagging is giving the same Recall Score of 0.59 than KNN without Bagging (original model).  \r\n",
    "\r\n",
    "Overall, Bagging Classifier is doing a better job than Pasting."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adaboost Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Adaboost Classifier with Decision Tree\r\n",
    "\r\n",
    "from sklearn.ensemble import AdaBoostClassifier\r\n",
    "\r\n",
    "grid_params ={'learning_rate': [0.5, 1, 1.5], 'n_estimators': [100, 200, 300], 'algorithm': ['SAMME', 'SAMME.R']}\r\n",
    "\r\n",
    "ada_tree = GridSearchCV(\r\n",
    "    AdaBoostClassifier(tree_bag, random_state=0), param_grid= grid_params, cv=5, scoring= 'recall')\r\n",
    "ada_tree.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print(\"Best parameters: {}\".format(ada_tree.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(ada_tree.best_score_))\r\n",
    "\r\n",
    "tree_ada= AdaBoostClassifier(tree_bag,**ada_tree.best_params_, random_state=0)\r\n",
    "tree_ada.fit(X_train, Y_train)\r\n",
    "print('Train_score : {}'.format(tree_ada.score(X_train, Y_train)))\r\n",
    "print('Test_score : {}'.format(tree_ada.score(X_test, Y_test)))\r\n",
    "\r\n",
    "tree_ada_Ypredict = tree_ada.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,tree_ada_Ypredict)))\r\n",
    "\r\n",
    "ensdl_results_df = ensdl_results_df.append(\r\n",
    "    {'model':'adaboost_decision_tree','test_score':tree_ada.score(X_test, Y_test),'recall_score':recall_score(Y_test,tree_ada_Ypredict)},ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'algorithm': 'SAMME', 'learning_rate': 1.5, 'n_estimators': 200}\n",
      "Best cross-validation score: 0.58\n",
      "Train_score : 0.9989333333333333\n",
      "Test_score : 0.7\n",
      "Recall :0.6122\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search on Adaboost Classifier with Decision Tree classifier gives the following best parameters: algorithm: SAMME, learning_rate: 1.5, n_estimators: 200. Cross Validation score is 0.58 and the Recall score is 0.61."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "# Adaboost Classifier with Random Forest\r\n",
    "\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "rf = RandomForestClassifier(max_depth= 6, max_features= 2, min_samples_leaf= 10, n_estimators= 10, random_state= 0)\r\n",
    "\r\n",
    "grid_params ={'learning_rate': [0.5, 1], 'n_estimators': [100, 300], 'algorithm': ['SAMME']}\r\n",
    "\r\n",
    "ada_rf = GridSearchCV(\r\n",
    "    AdaBoostClassifier(rf, random_state=0), param_grid= grid_params, cv=5, scoring= 'recall')\r\n",
    "ada_rf.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print(\"Best parameters: {}\".format(ada_rf.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(ada_rf.best_score_))\r\n",
    "\r\n",
    "rf_ada= AdaBoostClassifier(rf,**ada_rf.best_params_, random_state=0)\r\n",
    "rf_ada.fit(X_train, Y_train)\r\n",
    "print('Train_score : {}'.format(rf_ada.score(X_train, Y_train)))\r\n",
    "print('Test_score : {}'.format(rf_ada.score(X_test, Y_test)))\r\n",
    "\r\n",
    "rf_ada_Ypredict = rf_ada.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test, rf_ada_Ypredict)))\r\n",
    "\r\n",
    "ensdl_results_df = ensdl_results_df.append({'model':'adaboost_rf','test_score':rf_ada.score(X_test, Y_test),'recall_score':recall_score(Y_test, rf_ada_Ypredict)},ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'algorithm': 'SAMME', 'learning_rate': 0.5, 'n_estimators': 100}\n",
      "Best cross-validation score: 0.59\n",
      "Train_score : 0.8853333333333333\n",
      "Test_score : 0.7424\n",
      "Recall :0.6331\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search on Adaboost Classifier with Random Forest gives the following best parameters- algorithm: SAMME, learning_rate: 0.5, n_estimators: 100. Cross Validation score is 0.59 and the Test Recall score is 0.63."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gradient Boosting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "# grid search, logistic regression\r\n",
    "from  sklearn.ensemble import GradientBoostingClassifier\r\n",
    "grid_params= {'max_features': [2, 5, 10, 20], 'n_estimators': [100, 200, 500], 'learning_rate': [0.1, 0.25, 0.5, 0.75, 1]}\r\n",
    "\r\n",
    "grid_boost= GridSearchCV(\r\n",
    "    GradientBoostingClassifier(random_state=0), param_grid= grid_params, cv= 5, scoring='recall' )\r\n",
    "grid_boost.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print('Best parameters: {}'.format(grid_boost.best_params_))\r\n",
    "print('Best CV score:{}'.format(grid_boost.best_score_))\r\n",
    "\r\n",
    "grad_boost= GradientBoostingClassifier(**grid_boost.best_params_, random_state=0)\r\n",
    "grad_boost.fit(X_train, Y_train)\r\n",
    "print('Train_score : {}'.format(grad_boost.score(X_train, Y_train)))\r\n",
    "print('Test_score : {}'.format(grad_boost.score(X_test, Y_test)))\r\n",
    "\r\n",
    "grad_boost_Ypredict = grad_boost.predict(X_test)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test, grad_boost_Ypredict)))\r\n",
    "\r\n",
    "ensdl_results_df = ensdl_results_df.append({'model':'gradient_boosting','test_score':grad_boost.score(X_test, Y_test),'recall_score':recall_score(Y_test, grad_boost_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'learning_rate': 1, 'max_features': 5, 'n_estimators': 500}\n",
      "Best CV score:0.5847849648333912\n",
      "Train_score : 0.9426666666666667\n",
      "Test_score : 0.7216\n",
      "Recall :0.6179\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Grid Search on Gradient Boosting Classifier with Random Forest gives the following best parameters- learning_rate: 1, max_features: 5, n_estimators: 500. Cross Validation score is 0.58 and the Test Recall score is 0.62."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PCA Models :"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are using Principle Component Analysis for Dimension Reduction of the dataset. After that we run all the models from Project 1 on the new reduced dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "# Creating an empty DataFrame for the model results.\r\n",
    "\r\n",
    "pca_results_df = pd.DataFrame(columns=['model','test_score','recall_score'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "\r\n",
    "pca= PCA(n_components= 0.95)\r\n",
    "X_train_reduced= pca.fit_transform(X_train)\r\n",
    "X_test_reduced= pca.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "pca.n_components_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "After the dimension reduction we now have 20 new PCA features replacing the 34 original features."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## KNN Classifer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \r\n",
    "from sklearn.metrics import recall_score\r\n",
    "\r\n",
    "grid_params= {'n_neighbors': [3,4,5,8,10,15,20],'weights':['distance'],'metric':['euclidean']}\r\n",
    "\r\n",
    "pca_gs_knn= GridSearchCV(KNeighborsClassifier(), grid_params, cv= 5 ,scoring = 'recall',return_train_score=True)\r\n",
    "pca_gs_results= pca_gs_knn.fit(X_train, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(pca_gs_knn.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(pca_gs_knn.best_score_))\r\n",
    "\r\n",
    "pca_gs_best_knn = KNeighborsClassifier(n_neighbors = pca_gs_results.best_params_['n_neighbors'],metric=pca_gs_results.best_params_['metric'],weights=pca_gs_results.best_params_['weights'])\r\n",
    "pca_gs_best_knn.fit(X_train_reduced,Y_train)\r\n",
    "print(f'test score : {pca_gs_best_knn.score(X_test_reduced, Y_test)}')\r\n",
    "knn_Y_predict = pca_gs_best_knn.predict(X_test_reduced)\r\n",
    "print('Recall :{}'.format(recall_score(Y_test,knn_Y_predict)))\r\n",
    "\r\n",
    "pca_results_df = pca_results_df.append({'model':'knn','test_score':pca_gs_best_knn.score(X_test_reduced, Y_test),'recall_score':recall_score(Y_test,knn_Y_predict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'metric': 'euclidean', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best cross-validation score: 0.56\n",
      "test score : 0.6952\n",
      "Recall :0.5931558935361216\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search with cross-validation is- metric: euclidean, n_neighbors: 3, weights: distance. With these parameters, we run the KNN classifier, we get a test score of 0.69 and a recall score of 0.59."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "import warnings\r\n",
    "\r\n",
    "grid_params= {'penalty': ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'solver': ['lbfgs','saga',] }\r\n",
    "\r\n",
    "pca_Logreg = GridSearchCV(LogisticRegression(), param_grid = grid_params, cv = 5, n_jobs=-1, scoring= 'recall')\r\n",
    "warnings.filterwarnings('ignore')\r\n",
    "\r\n",
    "pca_best_logreg = pca_Logreg.fit(X_train_reduced, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(pca_Logreg.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(pca_Logreg.best_score_))\r\n",
    "\r\n",
    "pca_logL2= LogisticRegression(**pca_Logreg.best_params_)\r\n",
    "pca_logL2.fit(X_train_reduced, Y_train)\r\n",
    "print('train_score_l2 : {}'.format(pca_logL2.score(X_train_reduced, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(pca_logL2.score(X_test_reduced, Y_test)))\r\n",
    "\r\n",
    "Logreg_Y_predict = pca_logL2.predict(X_test_reduced)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,Logreg_Y_predict)))\r\n",
    "\r\n",
    "pca_results_df = pca_results_df.append({'model':'logistic_regression','test_score':pca_logL2.score(X_test_reduced, Y_test),'recall_score':recall_score(Y_test, Logreg_Y_predict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best cross-validation score: 0.59\n",
      "train_score_l2 : 0.748\n",
      "test_score_l2 : 0.7424\n",
      "Recall :0.6027\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search with cross-validation is- C: 0.1, penalty: l1, solver: saga. With these parameters, we run the Logistic Regression, we get a test score of 0.74 and a recall score of 0.60"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision tree"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "\r\n",
    "grid_params ={'criterion': ['gini', 'entropy'], 'max_depth': [2,5,7], 'min_samples_leaf':[5,10,15],  'random_state': [0]}\r\n",
    "\r\n",
    "pca_clf_tree = GridSearchCV(DecisionTreeClassifier(), param_grid = grid_params, cv = 5, n_jobs=-1, scoring= 'recall')\r\n",
    "\r\n",
    "pca_best_tree = pca_clf_tree.fit(X_train_reduced, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(pca_clf_tree.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(pca_clf_tree.best_score_))\r\n",
    "\r\n",
    "pca_tree = DecisionTreeClassifier(**pca_clf_tree.best_params_)\r\n",
    "pca_tree.fit(X_train_reduced, Y_train)\r\n",
    "\r\n",
    "print(\"Train score: {:.4f}\".format(pca_tree.score(X_train_reduced, Y_train)))\r\n",
    "print(\"Test score: {:.4f}\".format(pca_tree.score(X_test_reduced,Y_test)))\r\n",
    "\r\n",
    "tree_Ypredict = pca_tree.predict(X_test_reduced)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,tree_Ypredict)))\r\n",
    "\r\n",
    "pca_results_df = pca_results_df.append({'model':'decision_tree','test_score':pca_tree.score(X_test_reduced, Y_test),'recall_score':recall_score(Y_test, tree_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 5, 'random_state': 0}\n",
      "Best cross-validation score: 0.62\n",
      "Train score: 0.7125\n",
      "Test score: 0.7208\n",
      "Recall :0.6407\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search is- criterion: gini, max_depth: 2, min_samples_leaf: 5. With these parameters, we run the Decision Tree model, we get a test score of 0.72 and a recall score of 0.64"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LinearSVC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "from sklearn.svm import LinearSVC\r\n",
    "\r\n",
    "grid_params= {'penalty': ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100, 1000], 'random_state': [0] }\r\n",
    "\r\n",
    "pca_lsvc = GridSearchCV(LinearSVC(), param_grid = grid_params, cv = 5, n_jobs=-1, scoring= 'recall')\r\n",
    "\r\n",
    "best_lsvc = pca_lsvc.fit(X_train_reduced, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(pca_lsvc.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(pca_lsvc.best_score_))\r\n",
    "\r\n",
    "pca_ls= LinearSVC(**pca_lsvc.best_params_)\r\n",
    "pca_ls.fit(X_train_reduced, Y_train)\r\n",
    "print('train_score : {}'.format(pca_ls.score(X_train_reduced, Y_train)))\r\n",
    "print('test_score : {}'.format(pca_ls.score(X_test_reduced, Y_test)))\r\n",
    "\r\n",
    "pca_ls_Ypredict = pca_ls.predict(X_test_reduced)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,pca_ls_Ypredict)))\r\n",
    "\r\n",
    "pca_results_df = pca_results_df.append({'model':'linear_svc','test_score':pca_ls.score(X_test_reduced, Y_test),'recall_score':recall_score(Y_test, pca_ls_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'C': 0.01, 'penalty': 'l2', 'random_state': 0}\n",
      "Best cross-validation score: 0.59\n",
      "train_score : 0.7533333333333333\n",
      "test_score : 0.744\n",
      "Recall :0.6160\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search is- criterion: gini, max_depth: 2, min_samples_leaf: 5. The cross-validation score is 0.59. With these parameters, we run the Linear SVC model. We get a test score of 0.74 and a recall score of 0.61."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Kernel SVC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.metrics import recall_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "\r\n",
    "# kernel= poly\r\n",
    "\r\n",
    "grid_params_poly ={'kernel': ['poly'], 'C': [0.1,0.3], 'degree':[2,3,4],  'gamma': [0.1,0.3]}\r\n",
    "pca_poly = GridSearchCV(SVC(random_state=0), param_grid = grid_params_poly, cv = 5, scoring= 'recall',verbose=True)\r\n",
    "pca_poly.fit(X_train_reduced, Y_train)\r\n",
    "\r\n",
    "print(\"Best parameters: {}\".format(pca_poly.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(pca_poly.best_score_))\r\n",
    "\r\n",
    "pca_bestpoly = SVC(**pca_poly.best_params_)\r\n",
    "pca_bestpoly.fit(X_train_reduced,Y_train)\r\n",
    "\r\n",
    "print('train_score : {}'.format(pca_bestpoly.score(X_train_reduced, Y_train)))\r\n",
    "print('test_score : {}'.format(pca_bestpoly.score(X_test_reduced, Y_test)))\r\n",
    "pca_bestpoly_Ypredict = pca_bestpoly.predict(X_test_reduced)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,pca_bestpoly_Ypredict)))\r\n",
    "\r\n",
    "pca_results_df = pca_results_df.append({'model':'kernel_poly_svc','test_score':pca_bestpoly.score(X_test_reduced, Y_test),'recall_score':recall_score(Y_test, pca_bestpoly_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'C': 0.3, 'degree': 3, 'gamma': 0.3, 'kernel': 'poly'}\n",
      "Best cross-validation score: 0.53\n",
      "train_score : 0.7658666666666667\n",
      "test_score : 0.7464\n",
      "Recall :0.5913\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search is- C: 0.3, degree: 3, gamma: 0.3, kernel: poly. The cross-validation score is 0.53. With these parameters, we run the Kernel SVC. We get a test score of 0.75 and a recall score of 0.59."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "\r\n",
    "#kernel= rbf\r\n",
    "grid_params ={'kernel': ['rbf'], 'C': [0.1,0.3], 'degree':[2,3,4],  'gamma': [0.1,0.3]}\r\n",
    "\r\n",
    "pca_rbf = GridSearchCV(SVC(random_state=0), param_grid = grid_params, cv = 5, scoring= 'recall',verbose=True)\r\n",
    "pca_rbf.fit(X_train_reduced, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(pca_rbf.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(pca_rbf.best_score_))\r\n",
    "\r\n",
    "pca_bestrbf = SVC(**pca_rbf.best_params_)\r\n",
    "pca_bestrbf.fit(X_train_reduced, Y_train)\r\n",
    "\r\n",
    "print('train_score : {}'.format(pca_bestrbf.score(X_train_reduced, Y_train)))\r\n",
    "print('test_score : {}'.format(pca_bestrbf.score(X_test_reduced, Y_test)))\r\n",
    "\r\n",
    "pca_bestrbf_Ypredict = pca_bestrbf.predict(X_test_reduced)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test,pca_bestrbf_Ypredict)))\r\n",
    "\r\n",
    "pca_results_df = pca_results_df.append({'model':'kernel_rbf_svc','test_score':pca_bestpoly.score(X_test_reduced, Y_test),'recall_score':recall_score(Y_test, pca_bestrbf_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'C': 0.1, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best cross-validation score: 0.64\n",
      "train_score : 0.7464\n",
      "test_score : 0.748\n",
      "Recall :0.6502\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search is- C: 0.1, degree: 2, gamma: 0.1, kernel: rbf. With these parameters, we run the Kernel SVC. We get a test score of 0.75 and a recall score of 0.65."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "\r\n",
    "#kernel= linear\r\n",
    "grid_params ={'kernel': ['linear'], 'C': [0.1,0.3], 'degree':[2,3,4],  'gamma': [0.1,0.3]}\r\n",
    "\r\n",
    "pca_lin = GridSearchCV(SVC(random_state=0), param_grid = grid_params, cv = 5, scoring= 'recall',verbose=True)\r\n",
    "\r\n",
    "pca_lin.fit(X_train_reduced, Y_train)\r\n",
    "\r\n",
    "print(\"Best parameters: {}\".format(pca_lin.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(pca_lin.best_score_))\r\n",
    "\r\n",
    "pca_bestlin = SVC(**pca_lin.best_params_)\r\n",
    "pca_bestlin.fit(X_train_reduced,Y_train)\r\n",
    "\r\n",
    "print('train_score_l2 : {}'.format(pca_bestlin.score(X_train_reduced, Y_train)))\r\n",
    "print('test_score_l2 : {}'.format(pca_bestlin.score(X_test_reduced, Y_test)))\r\n",
    "\r\n",
    "pca_bestlin_Ypredict = pca_bestlin.predict(X_test_reduced)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test, pca_bestlin_Ypredict)))\r\n",
    "\r\n",
    "pca_results_df = pca_results_df.append({'model':'kernel_linear_svc','test_score':pca_bestpoly.score(X_test_reduced, Y_test),'recall_score':recall_score(Y_test, pca_bestlin_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Best parameters: {'C': 0.1, 'degree': 2, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Best cross-validation score: 0.64\n",
      "train_score_l2 : 0.7362666666666666\n",
      "test_score_l2 : 0.7424\n",
      "Recall :0.6882\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search is- C: 0.1, degree: 2, gamma: 0.1, kernel: linear. With these parameters, we run the Kernel SVC. We get a test score of 0.74 and a recall score of 0.69."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "grid_params ={'n_estimators': [100, 200, 500], 'max_depth': [2,4,6], 'min_samples_leaf':[5,10],  'random_state': [0], 'max_features' : [2]}\r\n",
    "\r\n",
    "pca_rf = GridSearchCV(RandomForestClassifier(), param_grid = grid_params, cv = 5, n_jobs=-1, scoring= 'recall')\r\n",
    "\r\n",
    "pca_rf.fit(X_train_reduced, Y_train)\r\n",
    "print(\"Best parameters: {}\".format(pca_rf.best_params_))\r\n",
    "print(\"Best cross-validation score: {:.2f}\".format(pca_rf.best_score_))\r\n",
    "\r\n",
    "pca_RForest= RandomForestClassifier(**pca_rf.best_params_)\r\n",
    "pca_RForest.fit(X_train_reduced, Y_train)\r\n",
    "\r\n",
    "print(\"Train score: {:.4f}\".format(pca_RForest.score(X_train_reduced, Y_train)))\r\n",
    "print(\"Test score: {:.4f}\".format(pca_RForest.score(X_test_reduced, Y_test)))\r\n",
    "\r\n",
    "pca_RForest_Ypredict = pca_RForest.predict(X_test_reduced)\r\n",
    "print('Recall :{:.4f}'.format(recall_score(Y_test, pca_RForest_Ypredict)))\r\n",
    "\r\n",
    "pca_results_df = pca_results_df.append({'model':'random_forest','test_score':pca_bestpoly.score(X_test_reduced, Y_test),'recall_score':recall_score(Y_test, pca_RForest_Ypredict)},ignore_index=True)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best parameters: {'max_depth': 6, 'max_features': 2, 'min_samples_leaf': 10, 'n_estimators': 100, 'random_state': 0}\n",
      "Best cross-validation score: 0.51\n",
      "Train score: 0.7805\n",
      "Test score: 0.7536\n",
      "Recall :0.5513\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the model after Grid Search is- max_depth: 6, max_features: 2, min_samples_leaf: 10, n_estimators: 100. With these parameters, we run the Random Forest model. The test score is 0.75 and the recall score is 0.55."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison\r\n",
    "\r\n",
    "Now we compare the results of the original models against that of the PCA reduced dataset and check if the PCA method improves or reduces the original models' results."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "# Compare the original models with PCA models\r\n",
    "print('Original Model Results')\r\n",
    "results_recall_df\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original Model Results\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 model  test_score  recall_score\n",
       "0                  knn      0.7056      0.593156\n",
       "1  logistic_regression      0.6992      0.642586\n",
       "2        decision_tree      0.7576      0.591255\n",
       "3           linear_svc      0.6504      0.673004\n",
       "4      kernel_poly_svc      0.7376      0.695817\n",
       "5       kernel_rbf_svc      0.7496      0.623574\n",
       "6    kernel_linear_svc      0.7360      0.505703\n",
       "7        random_forest      0.7632      0.576046"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.7056</td>\n",
       "      <td>0.593156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.642586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.591255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear_svc</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.673004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kernel_poly_svc</td>\n",
       "      <td>0.7376</td>\n",
       "      <td>0.695817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kernel_rbf_svc</td>\n",
       "      <td>0.7496</td>\n",
       "      <td>0.623574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kernel_linear_svc</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.505703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.576046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "print('PCA Model Results')\r\n",
    "pca_results_df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PCA Model Results\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 model  test_score  recall_score\n",
       "0                  knn      0.6952      0.593156\n",
       "1  logistic_regression      0.7424      0.602662\n",
       "2        decision_tree      0.7208      0.640684\n",
       "3           linear_svc      0.7440      0.615970\n",
       "4      kernel_poly_svc      0.7464      0.591255\n",
       "5       kernel_rbf_svc      0.7464      0.650190\n",
       "6    kernel_linear_svc      0.7464      0.688213\n",
       "7        random_forest      0.7464      0.551331"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.6952</td>\n",
       "      <td>0.593156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.602662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.7208</td>\n",
       "      <td>0.640684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear_svc</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.615970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kernel_poly_svc</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.591255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kernel_rbf_svc</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.650190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kernel_linear_svc</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.688213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.551331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "combined_results = results_recall_df.merge(pca_results_df,how='outer',on='model',suffixes=('','_pca'))\r\n",
    "combined_results"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 model  test_score  recall_score  test_score_pca  \\\n",
       "0                  knn      0.7056      0.593156          0.6952   \n",
       "1  logistic_regression      0.6992      0.642586          0.7424   \n",
       "2        decision_tree      0.7576      0.591255          0.7208   \n",
       "3           linear_svc      0.6504      0.673004          0.7440   \n",
       "4      kernel_poly_svc      0.7376      0.695817          0.7464   \n",
       "5       kernel_rbf_svc      0.7496      0.623574          0.7464   \n",
       "6    kernel_linear_svc      0.7360      0.505703          0.7464   \n",
       "7        random_forest      0.7632      0.576046          0.7464   \n",
       "\n",
       "   recall_score_pca  \n",
       "0          0.593156  \n",
       "1          0.602662  \n",
       "2          0.640684  \n",
       "3          0.615970  \n",
       "4          0.591255  \n",
       "5          0.650190  \n",
       "6          0.688213  \n",
       "7          0.551331  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>test_score_pca</th>\n",
       "      <th>recall_score_pca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.7056</td>\n",
       "      <td>0.593156</td>\n",
       "      <td>0.6952</td>\n",
       "      <td>0.593156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.6992</td>\n",
       "      <td>0.642586</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.602662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decision_tree</td>\n",
       "      <td>0.7576</td>\n",
       "      <td>0.591255</td>\n",
       "      <td>0.7208</td>\n",
       "      <td>0.640684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear_svc</td>\n",
       "      <td>0.6504</td>\n",
       "      <td>0.673004</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.615970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kernel_poly_svc</td>\n",
       "      <td>0.7376</td>\n",
       "      <td>0.695817</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.591255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kernel_rbf_svc</td>\n",
       "      <td>0.7496</td>\n",
       "      <td>0.623574</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.650190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kernel_linear_svc</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.505703</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.688213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.576046</td>\n",
       "      <td>0.7464</td>\n",
       "      <td>0.551331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following Barplot shows Comparison of the Original Models with the PCA models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    " import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "combined_results_modified= pd.melt(combined_results.drop(['test_score','test_score_pca'],axis=1), id_vars= 'model')\r\n",
    "ax = plt.subplot(111)\r\n",
    "sns.barplot(data= combined_results_modified, x= 'value', y= 'model', hue= 'variable')\r\n",
    "plt.xlim(0.4,None)\r\n",
    "box = ax.get_position()\r\n",
    "ax.legend(loc= 'upper right',bbox_to_anchor=(1.5,1))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x136679935b0>"
      ]
     },
     "metadata": {},
     "execution_count": 65
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Upon first glance, we see that there are three models that have a higher recall score after dimension reduction- Kernel SVC (linear) especially has a significant improvement."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Results Comparison for:\r\n",
    "\r\n",
    "(1) KNN model : The Recall scores remains unchanged with the PCA method.\r\n",
    "\r\n",
    "(2) Logistic Regression model: the test score has improved with PCA method but the Recall Score has reduced from 0.64 to 0.60.\r\n",
    "\r\n",
    "(3) Decision Tree: The model has improved with PCA method from 0.59 to 0.64 Recall Score.\r\n",
    "\r\n",
    "(4) Linear SVC: The test score has improved with PCA method from 0.65 to 0.74 but the Recall Score has reduced from 0.67 to 0.62.\r\n",
    "\r\n",
    "(5) Kernel SVC (poly): The Recall score has significantly reduced from 0.70 to 0.59 with PCA method.\r\n",
    "\r\n",
    "(6) Kernel SVC (rbf): The recall score has slightly improved with the PCA method from 0.62 to 0.65. The test score remains unchanged.\r\n",
    "\r\n",
    "(7) Kernel SVC (linear): The test score has slightly improved and the recall score has greatly improved from 0.50 to 0.69. \r\n",
    "\r\n",
    "(8) Random Forest: Both test score and recall score have slightly reduced with PCA method.\r\n",
    "\r\n",
    "\r\n",
    "**Conclusion:** Using PCA has improved the Decision Tree and the Kernel SVC (rbf and linear), models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deep Learning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lastly we are building a deep learning model. For the model, we use Sequential() and add 2 hidden layers. We use Grid Search on Keras Clasiifier to find the best parameters- batch size and epochs.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# from keras.models import Sequential\r\n",
    "\r\n",
    "from tensorflow.keras import Sequential\r\n",
    "from tensorflow.random import set_seed\r\n",
    "from keras.layers import Dense\r\n",
    "import numpy\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
    "def create_model():\r\n",
    "    #create model\r\n",
    "    model = Sequential()\r\n",
    "    model.add(Dense(20, input_dim=34, activation='relu'))\r\n",
    "    model.add(Dense(12, activation='relu'))\r\n",
    "    model.add(Dense(5, activation='relu'))\r\n",
    "    model.add(Dense(1, activation='sigmoid'))\r\n",
    "    #compile model\r\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Recall'])\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "\r\n",
    "set_seed(42)\r\n",
    "#np.random.seed(10)\r\n",
    "\r\n",
    "model_grid = KerasClassifier(build_fn = create_model, verbose = 0)\r\n",
    "\r\n",
    "param_grid = {'batch_size':[10,20,30] , 'epochs':[10, 50, 100],\r\n",
    "              'class_weight':[{0: 1,1:w} for w in [1, 2, 3]]}\r\n",
    "grid_search = GridSearchCV(estimator= model_grid, param_grid = param_grid, cv = 5, scoring='recall')\r\n",
    "\r\n",
    "grid_search_result = grid_search.fit(X_train, Y_train)\r\n",
    "\r\n",
    "print(grid_search.best_params_)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'batch_size': 30, 'class_weight': {0: 1, 1: 3}, 'epochs': 10}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters after the grid search is: batch_size: 30, class_weight: {0: 1, 1: 3}, epochs: 10. With these parameters we run the Deep Learning Model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "#fix random seed for reproducibility\r\n",
    "#numpy.random.seed(10)\r\n",
    "set_seed(42)\r\n",
    "\r\n",
    "# create model\r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(20, input_dim=34, activation='relu'))\r\n",
    "model.add(Dense(12, activation='relu'))\r\n",
    "model.add(Dense(5, activation='relu'))\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "# Compile model\r\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Recall', 'accuracy'])\r\n",
    "model.fit(X_train, Y_train, epochs= 10, batch_size=30, verbose=0,class_weight={0:1,1:3})\r\n",
    "dl_y_predict = model.predict(X_test)\r\n",
    "scores = model.evaluate(X_test, Y_test)\r\n",
    "print('Recall Score : {}'.format(scores[1]))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40/40 [==============================] - 0s 792us/step - loss: 0.6295 - recall: 0.7243 - accuracy: 0.7224\n",
      "Recall Score : 0.7243345975875854\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For the Deep Learning model, the Accuracy of the test set is 0.72 and the Recall score is 0.72. This model is performing better than the other models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best parameters for the Deep Learning model after Grid Search is- epochs: 10, batch_size: 20. With these parameters, the test score is 0.71 and the recall score is 0.73."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "ensdl_results_df = ensdl_results_df.append({'model':'deep_learning','test_score':scores[2],'recall_score':scores[1]},ignore_index=True)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Best Model Prediction\r\n",
    "\r\n",
    "Finally, we check all the ensemble and deep learning model results to see which is giving the best recall value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "print('Ensemble and Deep Learning models')\r\n",
    "ensdl_results_df"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Ensemble and Deep Learning models\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    model  test_score  recall_score\n",
       "0         hard_voting_cls      0.7296      0.678707\n",
       "1         soft_voting_cls      0.7504      0.629278\n",
       "2   bagging_decision_tree      0.7664      0.615970\n",
       "3             bagging_knn      0.7704      0.593156\n",
       "4   pasting_decision_tree      0.7672      0.612167\n",
       "5             pasting_knn      0.7632      0.566540\n",
       "6  adaboost_decision_tree      0.7000      0.612167\n",
       "7             adaboost_rf      0.7424      0.633080\n",
       "8       gradient_boosting      0.7216      0.617871\n",
       "9           deep_learning      0.7224      0.724335"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_score</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hard_voting_cls</td>\n",
       "      <td>0.7296</td>\n",
       "      <td>0.678707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soft_voting_cls</td>\n",
       "      <td>0.7504</td>\n",
       "      <td>0.629278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagging_decision_tree</td>\n",
       "      <td>0.7664</td>\n",
       "      <td>0.615970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bagging_knn</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.593156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pasting_decision_tree</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>0.612167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pasting_knn</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>0.566540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adaboost_decision_tree</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.612167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost_rf</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>0.633080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gradient_boosting</td>\n",
       "      <td>0.7216</td>\n",
       "      <td>0.617871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>deep_learning</td>\n",
       "      <td>0.7224</td>\n",
       "      <td>0.724335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Of all the models, including original and PCA models, the Deep Learning model is giving the best Recall Score of 0.72 with an accuracy score of 0.72. Hence Deep Learning is the best model. We run the model again."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "set_seed(42)\r\n",
    "\r\n",
    "# create model\r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(20, input_dim=34, activation='relu'))\r\n",
    "model.add(Dense(12, activation='relu'))\r\n",
    "model.add(Dense(5, activation='relu'))\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "# Compile model\r\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['Recall', 'accuracy'])\r\n",
    "model.fit(X_train, Y_train, epochs= 10, batch_size=30, verbose=0,class_weight={0:1,1:3})\r\n",
    "dl_y_predict = model.predict(X_test)\r\n",
    "scores = model.evaluate(X_test, Y_test)\r\n",
    "print('Accuracy Score : {}'.format(scores[2]))\r\n",
    "print('Recall Score : {}'.format(scores[1]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40/40 [==============================] - 0s 951us/step - loss: 0.6295 - recall: 0.7243 - accuracy: 0.7224\n",
      "Accuracy Score : 0.7224000096321106\n",
      "Recall Score : 0.7243345975875854\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "057734934c37b6046e29060fbd45296387f602e39f8283d7c00d9ff715b1d75a"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}